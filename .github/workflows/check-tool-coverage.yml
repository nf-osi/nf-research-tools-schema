name: Check Tool Coverage and Suggest Novel Tools
# Workflow for automated tool mining and coverage analysis

on:
  pull_request:
    types: [closed]
    branches:
      - main
  workflow_dispatch:  # Allow manual triggering
    inputs:
      ai_validation:
        description: 'Run AI validation on mined tools using Goose'
        required: false
        type: boolean
        default: true
      max_publications:
        description: 'Maximum number of publications to mine (blank = all)'
        required: false
        type: string
        default: ''
      force_rereviews:
        description: 'Force re-review of already-reviewed publications'
        required: false
        type: boolean
        default: false
      skip_title_screening:
        description: 'Skip title screening (use existing screened_publications.csv)'
        required: false
        type: boolean
        default: false
      skip_abstract_screening:
        description: 'Skip abstract screening (use existing abstract_screened_publications.csv)'
        required: false
        type: boolean
        default: false

permissions:
  contents: read
  issues: write

# Cancel previous runs if a new one is triggered
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  analyze-coverage:
    runs-on: ubuntu-latest
    timeout-minutes: 360  # 6 hours - GitHub Actions maximum
    # Only run if: (1) manual trigger, OR (2) PR was merged from annotation review workflow
    if: github.event_name == 'workflow_dispatch' || (github.event_name == 'pull_request' && github.event.pull_request.merged == true && contains(github.event.pull_request.labels.*.name, 'automated-annotation-review'))

    env:
      ENABLE_AI_VALIDATION: ${{ github.event.inputs.ai_validation != 'false' }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r tool_coverage/requirements.txt

      - name: Check for ANTHROPIC_API_KEY
        id: check_api_key
        run: |
          if [ -n "${{ secrets.ANTHROPIC_API_KEY }}" ]; then
            echo "api_key_exists=true" >> $GITHUB_OUTPUT
            echo "‚úÖ ANTHROPIC_API_KEY is configured"
          else
            echo "api_key_exists=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è  ANTHROPIC_API_KEY not found - AI validation will be skipped"
          fi

      - name: Cache Goose CLI
        if: steps.check_api_key.outputs.api_key_exists == 'true'
        id: cache-goose
        uses: actions/cache@v4
        with:
          path: ~/goose-bin
          key: goose-1.23.2-linux-x86_64

      - name: Install Goose CLI
        if: steps.check_api_key.outputs.api_key_exists == 'true' && steps.cache-goose.outputs.cache-hit != 'true'
        run: |
          echo "Installing Goose CLI for AI validation..."
          # Download pre-built binary from GitHub releases
          GOOSE_VERSION="1.23.2"
          mkdir -p ~/goose-bin
          wget -q https://github.com/block/goose/releases/download/v${GOOSE_VERSION}/goose-x86_64-unknown-linux-gnu.tar.bz2
          tar -xjf goose-x86_64-unknown-linux-gnu.tar.bz2 -C ~/goose-bin
          chmod +x ~/goose-bin/goose
          rm goose-x86_64-unknown-linux-gnu.tar.bz2

      - name: Add Goose to PATH
        if: steps.check_api_key.outputs.api_key_exists == 'true'
        run: |
          echo "$HOME/goose-bin" >> $GITHUB_PATH
          ~/goose-bin/goose --version

      - name: Download artifacts from previous run (if skipping steps)
        if: github.event.inputs.skip_title_screening == 'true' || github.event.inputs.skip_abstract_screening == 'true'
        uses: dawidd6/action-download-artifact@v3
        with:
          workflow: check-tool-coverage.yml
          name: tool-coverage-reports
          path: .
          if_no_artifact_found: warn
        continue-on-error: true

      - name: Prepare publication list (bench + clinical queries)
        id: prep_list
        env:
          SYNAPSE_AUTH_TOKEN: ${{ secrets.SYNAPSE_AUTH_TOKEN }}
        run: |
          if [ "${{ github.event.inputs.skip_title_screening }}" == "true" ] || [ "${{ github.event.inputs.skip_abstract_screening }}" == "true" ]; then
            echo "‚è≠Ô∏è  Skipping publication list preparation (using existing artifacts)"
            echo "prep_complete=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Step 1: Preparing publication lists for all tool types..."
          echo "Running both bench and clinical queries to capture all 9 tool types"

          # Create outputs directory
          mkdir -p tool_coverage/outputs

          # Run bench science query (computational, PDX, organoids, lab tools)
          echo "1a. Bench science query (computational, PDX, organoids, antibodies, cell lines)..."
          python tool_coverage/scripts/prepare_publication_list.py \
            --query-type bench \
            --output tool_coverage/outputs/publication_list_bench.csv \
            2>&1 | tee tool_coverage/outputs/prep_list_bench.log || echo "bench_failed=true" >> $GITHUB_OUTPUT

          # Run clinical assessment query (questionnaires, scales, PROMs)
          echo "1b. Clinical assessment query (SF-36, PROMIS, PedsQL, outcome measures)..."
          python tool_coverage/scripts/prepare_publication_list.py \
            --query-type clinical \
            --output tool_coverage/outputs/publication_list_clinical.csv \
            2>&1 | tee tool_coverage/outputs/prep_list_clinical.log || echo "clinical_failed=true" >> $GITHUB_OUTPUT

          # Merge publication lists (deduplicate by PMID, merge query_types)
          echo "1c. Merging publication lists..."
          python3 <<'EOF' || echo "merge_failed=true" >> $GITHUB_OUTPUT
          import pandas as pd

          bench = pd.read_csv('tool_coverage/outputs/publication_list_bench.csv')
          clinical = pd.read_csv('tool_coverage/outputs/publication_list_clinical.csv')

          # Concatenate both query results
          merged = pd.concat([bench, clinical], ignore_index=True)

          # Deduplicate by PMID, merging query_types for publications in both queries
          # Example: If PMID appears in both bench and clinical, query_type becomes 'bench,clinical'
          merged = merged.groupby('pmid', as_index=False).agg({
              'title': 'first',
              'doi': 'first',
              'journal': 'first',
              'year': 'first',
              'query_type': lambda x: ','.join(sorted(set(x))),  # Merge query types
              'source': 'first'
          })

          merged.to_csv('tool_coverage/outputs/publication_list.csv', index=False)
          print(f'Merged: {len(bench)} bench + {len(clinical)} clinical -> {len(merged)} unique publications')
          print(f'  Publications in both queries: {len(bench) + len(clinical) - len(merged)}')
          EOF

          # Only mark complete if no errors
          if [ ! -f $GITHUB_OUTPUT ] || ! grep -q "_failed=true" $GITHUB_OUTPUT; then
            echo "prep_complete=true" >> $GITHUB_OUTPUT
          fi

      - name: Screen publication titles with Haiku
        id: screening
        if: steps.check_api_key.outputs.api_key_exists == 'true' && steps.prep_list.outputs.prep_complete == 'true' && github.event.inputs.skip_title_screening != 'true'
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          echo "Step 2: Pre-screening titles with Haiku (research vs clinical)..."

          # Build command
          CMD="python tool_coverage/scripts/screen_publication_titles.py"

          # Add max publications limit if specified
          if [ -n "${{ github.event.inputs.max_publications }}" ]; then
            CMD="$CMD --max-publications ${{ github.event.inputs.max_publications }}"
          fi

          # Run screening (uses cheap Haiku model via direct API)
          echo "Running: $CMD"
          $CMD 2>&1 | tee tool_coverage/outputs/screening_output.log || echo "screening_failed=true" >> $GITHUB_OUTPUT

          echo "screening_complete=true" >> $GITHUB_OUTPUT

      - name: Use existing title screening results
        id: screening_skipped
        if: github.event.inputs.skip_title_screening == 'true'
        run: |
          echo "‚è≠Ô∏è  Skipping title screening - using existing results"
          if [ -f "tool_coverage/outputs/screened_publications.csv" ]; then
            echo "   ‚úÖ Found existing screened_publications.csv"
            echo "screening_complete=true" >> $GITHUB_OUTPUT
          else
            echo "   ‚ùå ERROR: screened_publications.csv not found!"
            echo "   Please upload artifacts from previous run or run without skip flag"
            exit 1
          fi

      - name: Screen publication abstracts with Haiku
        id: abstract_screening
        if: steps.check_api_key.outputs.api_key_exists == 'true' && (steps.screening.outputs.screening_complete == 'true' || steps.screening_skipped.outputs.screening_complete == 'true') && github.event.inputs.skip_abstract_screening != 'true'
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          SYNAPSE_AUTH_TOKEN: ${{ secrets.SYNAPSE_AUTH_TOKEN }}
        run: |
          echo "Step 2b: Screening abstracts with Haiku (NF tool usage/development)..."

          # Build command
          CMD="python tool_coverage/scripts/screen_publication_abstracts.py"

          # Add max publications limit if specified
          if [ -n "${{ github.event.inputs.max_publications }}" ]; then
            CMD="$CMD --max-publications ${{ github.event.inputs.max_publications }}"
          fi

          # Run abstract screening (uses Haiku to check for NF tool usage)
          echo "Running: $CMD"
          $CMD 2>&1 | tee tool_coverage/outputs/abstract_screening_output.log || echo "abstract_screening_failed=true" >> $GITHUB_OUTPUT

          # Update the screened_publications.csv to be the output of abstract screening
          if [ -f "tool_coverage/outputs/abstract_screened_publications.csv" ]; then
            cp tool_coverage/outputs/abstract_screened_publications.csv tool_coverage/outputs/screened_publications.csv
            echo "abstract_screening_complete=true" >> $GITHUB_OUTPUT
          fi

      - name: Use existing abstract screening results
        id: abstract_screening_skipped
        if: github.event.inputs.skip_abstract_screening == 'true'
        run: |
          echo "‚è≠Ô∏è  Skipping abstract screening - using existing results"
          if [ -f "tool_coverage/outputs/abstract_screened_publications.csv" ]; then
            echo "   ‚úÖ Found existing abstract_screened_publications.csv"
            # Copy to screened_publications.csv for next steps
            cp tool_coverage/outputs/abstract_screened_publications.csv tool_coverage/outputs/screened_publications.csv
            echo "abstract_screening_complete=true" >> $GITHUB_OUTPUT
          else
            echo "   ‚ùå ERROR: abstract_screened_publications.csv not found!"
            echo "   Please upload artifacts from previous run or run without skip flag"
            exit 1
          fi

      - name: Apply timeout protection
        id: timeout
        if: steps.abstract_screening.outputs.abstract_screening_complete == 'true' || steps.abstract_screening_skipped.outputs.abstract_screening_complete == 'true'
        run: |
          echo "Applying timeout protection to prevent workflow timeout..."

          # Apply timeout protection using screened publications
          python tool_coverage/scripts/timeout_protection.py \
            --publications-file tool_coverage/outputs/screened_publications.csv \
            --output-file tool_coverage/outputs/screened_publications_capped.csv \
            --deferred-file tool_coverage/outputs/publications_deferred.txt \
            --time-per-publication 3.6 > timeout_result.json

          # Check if publications were capped
          CAPPED=$(python -c "import json; data=json.load(open('timeout_result.json')); print(data.get('capped', False))")

          if [ "$CAPPED" == "True" ]; then
            echo "‚ö†Ô∏è  Publications capped to fit within 6-hour timeout limit"
            echo "capped=true" >> $GITHUB_OUTPUT

            # Use capped list for mining
            cp tool_coverage/outputs/screened_publications_capped.csv tool_coverage/outputs/screened_publications.csv

            FINAL_COUNT=$(wc -l < tool_coverage/outputs/screened_publications.csv)
            DEFERRED_COUNT=$(wc -l < tool_coverage/outputs/publications_deferred.txt)

            echo "Publications to process (this run): $FINAL_COUNT"
            echo "Publications deferred (next run): $DEFERRED_COUNT"
          else
            echo "‚úì All publications fit within timeout"
            echo "capped=false" >> $GITHUB_OUTPUT
          fi

      - name: Extract publication sections
        id: mining
        if: steps.prep_list.outputs.prep_complete == 'true'
        env:
          SYNAPSE_AUTH_TOKEN: ${{ secrets.SYNAPSE_AUTH_TOKEN }}
        run: |
          echo "Step 3: Extracting publication sections for Sonnet review..."

          # Use improved mining script (tool mining disabled by default)
          CMD="python tool_coverage/scripts/mine_publications_improved.py"

          # Input is already capped by timeout protection
          CMD="$CMD --input tool_coverage/outputs/screened_publications.csv"
          CMD="$CMD --output tool_coverage/outputs/processed_publications_improved.csv"

          # Note: Tool mining is disabled by default. To enable, add --enable-tool-mining flag
          # This extracts intro, methods, results, discussion for later Sonnet review
          echo "Running: $CMD"
          $CMD 2>&1 | tee tool_coverage/outputs/mining_output.log || echo "mining_failed=true" >> $GITHUB_OUTPUT

          # Use improved output as the main processed_publications.csv
          if [ -f "tool_coverage/outputs/processed_publications_improved.csv" ]; then
            cp tool_coverage/outputs/processed_publications_improved.csv tool_coverage/outputs/processed_publications.csv
          fi

          echo "mining_complete=true" >> $GITHUB_OUTPUT

      - name: Run AI validation with Sonnet
        id: validation
        if: steps.check_api_key.outputs.api_key_exists == 'true'
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          echo "Running AI validation on publications (Sonnet review of full text)..."

          # Build command with optional flags
          # Note: --include-unlinked is now the default (fetches from NF portal + unlinked tools pubs)
          CMD="python tool_coverage/scripts/run_publication_reviews.py --mining-file tool_coverage/outputs/processed_publications.csv --parallel-workers 4"

          # Add force re-reviews flag if specified
          if [ "${{ github.event.inputs.force_rereviews }}" = "true" ]; then
            CMD="$CMD --force-rereviews"
          fi

          # Run validation
          echo "Running: $CMD"
          $CMD 2>&1 | tee tool_coverage/outputs/validation_output.log || echo "validation_failed=true" >> $GITHUB_OUTPUT

          echo "validation_complete=true" >> $GITHUB_OUTPUT

      - name: Apply pattern improvements
        id: pattern_improvements
        if: steps.validation.outputs.validation_complete == 'true'
        run: |
          echo "Applying AI-suggested pattern improvements..."
          python tool_coverage/scripts/apply_pattern_suggestions.py 2>&1 | tee pattern_improvements_output.log

          # Check if any files were modified
          if [ -f "tool_coverage/config/mining_patterns.json" ] || [ -f "PATTERN_IMPROVEMENTS.md" ]; then
            echo "pattern_improvements_applied=true" >> $GITHUB_OUTPUT
          fi

      - name: Format validated results for submission
        id: formatting
        run: |
          echo "Formatting AI-validated results into VALIDATED_*.csv files..."
          if [ -f "tool_reviews/validation_summary.json" ] || [ -f "tool_reviews/potentially_missed_tools.csv" ]; then
            python tool_coverage/scripts/format_validation_for_submission.py 2>&1 | tee tool_coverage/outputs/formatting_output.log
            echo "formatting_complete=true" >> $GITHUB_OUTPUT
          else
            echo "‚ö†Ô∏è Skipping formatting - no validation results found"
          fi

      - name: Analyze tool coverage
        id: coverage
        if: steps.prep_list.outputs.prep_complete == 'true'
        env:
          SYNAPSE_AUTH_TOKEN: ${{ secrets.SYNAPSE_AUTH_TOKEN }}
        run: |
          echo "Running coverage analysis with validated results..."
          python tool_coverage/scripts/analyze_missing_tools.py 2>&1 | tee tool_coverage/outputs/coverage_output.log

          # Extract key metrics for summary
          echo "coverage_complete=true" >> $GITHUB_OUTPUT

      - name: Generate summary report
        id: summary
        env:
          SYNAPSE_AUTH_TOKEN: ${{ secrets.SYNAPSE_AUTH_TOKEN }}
        run: |
          python tool_coverage/scripts/generate_coverage_summary.py > pr_body.md

          # Read the summary for the PR body
          echo "PR_BODY<<EOF" >> $GITHUB_OUTPUT
          cat pr_body.md >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Upload reports as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: tool-coverage-reports
          path: |
            tool_coverage/outputs/
            tool_reviews/
            pr_body.md
          if-no-files-found: warn
          retention-days: 30

      - name: Upload deferred publications
        if: steps.timeout.outputs.capped == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: deferred-publications-${{ github.run_id }}
          path: tool_coverage/outputs/publications_deferred.txt
          retention-days: 90

      - name: Clean up log files before PR
        if: steps.mining.outputs.mining_complete == 'true'
        run: |
          echo "Removing log files from outputs (kept in artifacts)..."
          find tool_coverage/outputs -name "*.log" -type f -delete
          echo "Log files removed from working directory"

      - name: Create Pull Request with results
        # Only create PR if mining step completed successfully
        if: steps.mining.outputs.mining_complete == 'true'
        uses: peter-evans/create-pull-request@v7
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: |
            Update tool coverage: automated mining results

            - Coverage report updated
            - Novel tools mined from publications
            - Ready for Synapse upload after review
          branch: tool-coverage-update-${{ github.run_number }}
          delete-branch: true
          title: 'üîç Tool Coverage Update - ${{ github.run_number }}'
          body-path: pr_body.md
          assignees: BelindaBGarana
          labels: |
            automated-mining
            tool-coverage
          add-paths: |
            tool_coverage/outputs/
            tool_coverage/config/mining_patterns.json
