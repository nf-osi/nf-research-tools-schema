{
  "pmid": "PMID:34106871",
  "title": "DINs: Deep Interactive Networks for Neurofibroma Segmentation in Neurofibromatosis Type 1 on Whole-Body MRI.",
  "abstract": "Neurofibromatosis type 1 (NF1) is an autosomal dominant tumor predisposition syndrome that involves the central and peripheral nervous systems. Accurate detection and segmentation of neurofibromas are essential for assessing tumor burden and longitudinal tumor size changes. Automatic convolutional neural networks (CNNs) are sensitive and vulnerable as tumors' variable anatomical location and heterogeneous appearance on MRI. In this study, wepropose deep interactive networks (DINs) to address the above limitations. User interactions guide the model to recognize complicated tumors and quickly adapt to heterogeneous tumors. We introduce a simple but effective Exponential Distance Transform (ExpDT) that converts user interactions into guide maps regarded as the spatial and appearance prior. Comparing with popular Euclidean and geodesic distances, ExpDT is more robust to various image sizes, which reserves the distribution of interactive inputs. Furthermore, to enhance the tumor-related features, we design a deep interactive module to propagate the guides into deeper layers. We train and evaluate DINs on three MRI data sets from NF1 patients. The experiment results yield significant improvements of 44% and 14% in DSC comparing with automated and other interactive methods, respectively. We also experimentally demonstrate the efficiency of DINs in reducing user burden when comparing with conventional interactive methods.",
  "authors": "Jian-Wei Zhang; Wei Chen; K Ina Ly; Xubin Zhang; Fan Yan; Justin Jordan; Gordon Harris; Scott Plotkin; Pengyi Hao; Wenli Cai",
  "journal": "IEEE journal of biomedical and health informatics",
  "publicationDate": "2022-02",
  "doi": "10.1109/JBHI.2021.3087735",
  "methods": "III. METHODS In the context of neurofibroma segmentation on WBMRI, we propose deep interactive neural networks (DINs) for 3D medical image semantic segmentation, which is inspired by deep object selection [ 11 ] for interactive segmentation of natural images and feature modulation [ 27 ], [ 28 ] for conditional controlling of the neural networks. DINs employed an encoder-decoder backbone embedded within the deep interactive module (DIM). The DIM influences neural network segmentation via the image-specific information generated from user interactions represented by the distance map. The structure of DINs is shown in  Fig. 2 . Furthermore, for efficient training of DINs, we propose a strategy to simulate user interactions in the training process, thereby avoiding creating thousands of training samples manually. This strategy can also be used to evaluate the performance of DINs and adjust the hyper-parameters quickly. A. Exponential distance transform The DT of a binary mask, specifies the minimum distances from each pixel to the boundaries of non-zero regions, where the distances may be signed to distinguish between the inside and outside of the non-zero regions. Instead of the boundaries, unsigned DTs compute minimum distances to the whole masked regions. Various unsigned DTs have been studied for image segmentation in the literature [ 11 ], [ 12 ], [ 29 ]. Given an N-Dimension gray image  I  and a corresponding binary mask   represents the image intensity at point x and  M , I ( x ) . Point set  M ( x ) \u2208 { 0 , 1 }  is defined as  S  that is considered the point set of user interactions. The DT of  { x \u2223 M ( x ) = 1 } I  concerning  is formulated as:\n S \nwhere  (1) D ( x , S , I ) = min x \u2032 \u2208 S d ( x , x \u2032 , I ) , \u2200 x \u2208 I ,  is a specific distance function between two points in an image. For Euclidean distance and geodesic distance,  d ( \u22c5 , \u22c5 )  can be uniformly defined as:\n d ( \u22c5 , \u22c5 ) \nwhere  (2) d ( x , y , I ) = min \u0393 \u2208 P x , y \u222b 0 1 \u03b1 \u2016 \u0393 \u2032 ( s ) \u2016 2 + \u03b2 ( \u2207 I \u22c5 u ) 2 d s ,  is the set of all paths between the point x and y, and  P x , y  is such a path, parameterized by  \u0393 ( s ) : \u211d \u2192 \u211d 2 .  s \u2208 [ 0 , 1 ]  is the derivative of  \u0393 \u2032 ( s )  with respect to  \u0393 ( s ) s  and   is a unit vector along the tangent direction of  u = \u0393 \u2032 / \u2016 \u0393 \u2032 \u2016 . If  \u0393 ,  \u03b2 = 0 Equation (1)  is called Euclidean distance transform, which is not conditioned on the image intensity and thus degenerates to  . If  D e u c ( x , S ) , it becomes a geodesic distance transform. When  \u03b1 = 0  and  \u03b1 \u2260 0 ,  \u03b2 \u2260 0 Equation (1)  is a combination of the two distances. A common characteristic of the two distance functions is that they strongly rely on the image size, which means that for images with different sizes, the intensity distribution is significantly different. We name the DT with this feature as \u201cglobal transform\u201d. An illustration of EDT, GDT and their blended DT is shown in  Fig. 3  ( c \u2013 e ). It can be seen that the grayscale (shown as the color bar) significantly varies from the image size (shown as the dotted box). Compared with popular CNN models taking fixed size images as input for classification problems [ 20 ], [ 30 ], FCN-like models, such as U-Net, remove densely connected layers and thus can accept input images of arbitrary sizes and produce correspondingly-sized outputs [ 25 ]. Furthermore, FCN-like models allow the size of inference images to be different from that of training images, which is crucial in the segmentation of large 3D medical images such as WBMRI due to limited GPU memory and insufficient training samples. For example, we may need to train a 3D U-Net with small volume patches due to the limited GPU memory, but inference with the whole volume as the inference saves the memory of storing gradients of parameters. Most of the operators in CNNs such as addition, multiplication, ReLU, convolution, and max pooling are either element-wise or window-wise [ 31 ], with which the predictions are hardly affected if the image patches were expanded or clipped (i.e., the size changes). However, the distribution of the integrated global DT corresponds to the actual feature size, and therefore inconsistent image sizes in training and inference stages lead to distribution inconsistency, which may impact the segmentation performance. Therefore, we propose a \u201clocal transform\u201d, exponential distance transform, to avoid being affected by the variable image sizes. The ExpDT is formulated as:\n \n (3) E x p D T ( x , S ) = max x \u2032 \u2208 S d e x p ( x , x \u2032 ) , \nwith  (4) d e x p ( x , y ) = \u03b3 exp ( \u2212 \u2225 x \u2212 y \u2225 2 2 2 \u03c3 2 )  the scale parameter, and  \u03b3 \u03c3  controlling the influence of the points in   on surrounding points. As shown in  S Fig. 3(f) , the ExpDT is a local-enhanced distance map that means pixels with high gray levels are tightly gathered near the points in  , and therefore ExpDT is hardly affected by the variable image sizes. When  S , ExpDT tends to form spikes at the point in  \u03c3 \u2192 + \u221e ; and when  S , ExpDT becomes flat and loses locality. Different from the previous two transforms that use  \u03c3 \u2192 0 min  to compute distances to S, ExpDT turns to use  max  due to the negative sign in  equation (4) . If we only considered from the perspective of DTs, ExpDT neither has global attributes nor combines image intensity. We argue that, with the proposed DINs framework, CNNs can still learn discriminative features from the local-enhanced ExpDT. B. Structure of DINs The structure of DINs follows the encoder-decoder scheme with skip connection like 3D U-Net [ 15 ]. But 3D U-Net is originally evaluated to segment organs with fixed size and balance pixel spacing, such as Xenopus kidney, and not suitable for the scenario of various neurofibromas. Considering that WBMRI has an approximate average shape of 20\u00d71080\u00d7321 with a pixel spacing of 10\u00d71.56\u00d71.56 mm , we fix the size of the input image to 10\u00d7512\u00d7160, which is about half the size of the original image. It should be noted that when the pixel spacing of an image differs significantly, isotropic resampling is not a good choice, due to the missing inter-slice information. Therefore, we build the backbone network with convolutional layers that have different kernel sizes and strides. There are four downsamplings in the coronal plane, but only once in the orthogonal direction. Instead of using max pooling layers, downsampling is implemented by large-stride convolution to save GPU memory and apply a larger batch size. Upsampling is performed by deconvolutional layers [ 32 ]. Commonly, batch normalization (BN), which is used to reduce internal covariate shift and stabilize training [ 33 ], has poor performance when confronted with small batch size [ 34 ]. In addition, Isensee  et al.  [ 35 ] experimentally demonstrate instance normalization [ 36 ] (IN) performs better than BN in medical images. Therefore, we apply IN after the convolutional layers, followed by ReLU activation. For clarity, we list all the details of the internal layers of DINs in  Table I . To incorporate user interactions into deep neural networks, we develop a deep interactive module (DIM). By leveraging feature modulation [ 27 ], the DIM embeds additional image-specific information into the network backbone and guides the model to focus on the features that are enhanced by the distance maps, or the so-called guide maps, as shown in  Fig. 2 . The DIM consists of an ExpDT, a max pooling layer, and a convolutional layer, transforming user interactions into guided maps of two different sizes (DIM output 1 and DIM output 2). Concretely, user interactions are transformed into a foreground guide map and a background guide map by ExpDT and are then integrated into the input layer by concatenating with the raw image as a three-channel input. The two guided maps are further encoded and integrated into the encoder\u2019s deepest layer to avoid the guide information being gradually diluted as more complex features are extracted. A detailed experiment regarding the position where the DIM outputs are inserted is placed in  Section V-C.3 . As shown in  Fig. 4 , downsampled guide maps are added to the output of the first normalization layer in the deepest layer of the encoder and followed by a ReLU activation function. The layers in decoder path do not need more integration due to the guide information passed from the skip connections. C. Simulating strategy Simulating user interactions in the training stage and evaluation stage can not only free users from the burdensome interactive work for generating thousands of training samples, but also accelerate the process of exploring the optimal hyperparameters. Our strategy of simulating user interactions is based on the work in [ 11 ] and extends to the setting of 3D images. Let  M  denote the ground truth segmentation of an image  I , and   denote the set of pixels of foreground objects satisfying  F . We define background regions surrounding objects as:\n M ( x ) = 1 , \u2200 x \u2208 F \nwhere  (5) B = { x \u2208 I \u2223 x \u2209 F , D e u c ( x , F ) < w } ,  is the Euclidean distance between the point x and the set  D e u c ( x , F ) , and  F w  is the bandwidth. When processing 2D natural images, Xu  et al.  [ 11 ] proposed to sample positive clicks from   randomly, and the number of sampled points followed a discrete uniform distribution from 1 to  F . Negative clicks were randomly selected from the whole background ( N p o s random selection ) and evenly select from B ( uniform selection ). The number of negative points did not exceed   but could be zero. However, if we directly use the same upper bound  N n e g  and  N p o s  in 3D images, user interactions will become quite sparse as the additional axis, which is experimentally demonstrated to be harmful to the model performance. Therefore, we adapt  N n e g  and  N p o s  to the 3D version as follow:\n N n e g (6) N p o s , 3 D = N p o s 3 / 2 N n e g , 3 D = N n e g 3 / 2 . This strategy maybe not the best choice, but it indeed is a simple and effective way to determine a better upper bound of the click numbers sampled in the training stage. In addition, positive and negative clicks from the  -pixel region near the boundaries should be avoided. Considering the fact of large inter-slice spacing of WBMRIs and infiltrative MRI appearance of neurofibromas, the restriction of  d m a r g i n  was only applied to individual slices. Finally, at least  d m a r g i n d ,  z d ,  y d  pixels should be kept between any two points in each dimension. x During the evaluation, simulation is performed by placing the next positive/negative click on the center of the largest error region acquired from the symmetric difference between the current prediction and ground truth. Specifically, if the largest error region   is part of a foreground object, then the next click  R x  is a positive point, whose coordinate is  , if  x = 1 / | R | \u2211 x i \u2208 R x i , we replace x x \u2209 R  by:\n f \nwhere  (7) x \u2032 = arg min y \u2208 ske ( R ) D e u c ( x , y ) ske ( ) is the skeleton [ R 37 ] of the region  . It means that x R \u2032  is the nearest point of x in the skeleton of  . This situation may occur when  R  is concave. In this way, we guarantee that the positive points will not be placed in the wrong region (background) and vice versa. The maximum number of clicks on a single study is limited to  R . we set a threshold DSC (see  n i n t e r s Section IV-B ) of   in cross-validation experiments. If the target threshold can not be achieved in  t D S C  clicks, we will terminate the interaction of the current study. n i n t e r s B. Comparison with other methods 1) State-of-the-art interactive methods: Cai  et al.  [ 3 ] perform volume measurements on the LRMRI data set using 3DQI software at Massachusetts General Hospital (MGH) and National Cancer Institute (NCI) and MEDx software at NCI.  Table IV  shows the results of NCI-3DQI - NCI-MEDx and MGH-3DQI - NCI-MEDx at the first two rows. We take the segmentation results of NCI-MEDx as the ground truth and use DINs on the LRMRI data set. Results in the last row indicate that DINs can achieve similar performance comparing with 3DQI. Notice that the results of NCI-3DQI and MGH-3DQI are finalized with various editing tools, while DINs are not for a fair comparison. 2) Deep CNN-based methods: A comparison between DINs and state-of-the-art medical image segmentation methods is shown in  Table V . One can observe that DINs outperform automated methods by 44%\u201363% and outperform \u201cnnU-Net + Dim output 1\u201d by 29%. Automated methods get low scores, while interactive methods have better performance with the help of user knowledge. The comparison between \u201cnnU-Net + Dim output 1\u201d and \u201cDINs (DIM output 1)\u201d indicates that DINs benefit from the proposed structure of feature extractor adapted to WBMRI. Finally, with the DIM output 2, DINs further increase the DSC by 2%, which suggests the effectiveness of integrating user knowledge into deeper layers. In addition, the p-values of t-test between the results of DINs and other methods are listed for reference. 3) Conventional interactive methods: We compare DINs with some conventional interactive segmentation methods, including Random Walk (RW) [ 24 ], Graph Cut (GC) [ 23 ] and Active Contour (AC) [ 42 ]. RW and GC treat the volume as a discrete static graph, performing segmentation with many positive and negative clicks by solving the linear system (RW) or min-cut (GC) problem. Commonly, to save computation time and reduce irrelevant information, a bounding box is provided before running these conventional approaches. Then the search space can be restricted to a smaller region. Therefore, we implement two versions of DINs: DINs-full.  Feeding the whole 3D volume into DINs for evaluation. DINs-box.  We manually create several bounding boxes in each volume with three criteria: (1) Spatially closer tumors are grouped into the same bounding box. (2) The heights and the widths of bounding boxes are at least 128 pixels, while depths are set as tight to the tumor boundaries as possible that is consistent with users\u2019 behavior. (3) There are no more than five bounding boxes in one case. Fig. 7(a)  presents the trend of DSC for DINs and conventional methods when the interactive points are continuously provided. RW, GC, AC, and DINs-box ran the algorithms within the volume of interest while DINs-full employs the entire 3D volume. In  Fig. 7 , we observe that RW and GC show a low DSC, which is caused by the limited information used to compute features. We notice that DINs-full only has a modest improvement compared with AC since AC needs to set a bounding box and adjust two thresholds for filtering backgrounds, which requires much more user efforts to precisely tune the thresholds. With additional bounding boxes, DINs-box significantly exceeds all of the other three conventional interactive methods. For a detailed comparison, we summarize the type of interactions, DSC, number of interactions, and running time in  Table VI . DINs-full has the minimum requirement of interactions to perform the segmentation, which substantially reduces the complexity of the interaction. With extra bounding boxes, DINs-box further improves segmentation accuracy and reduces both the user burden and the running time. Overall, as the number of interactions increases, DINs improve the segmentation accuracy more stably and successively. Furthermore, a substantial improvement can be made by providing a few bounding boxes for some difficult cases (DINs-box). This implies that DINs are more effective and flexible for interactive segmentation. 1) State-of-the-art interactive methods: Cai  et al.  [ 3 ] perform volume measurements on the LRMRI data set using 3DQI software at Massachusetts General Hospital (MGH) and National Cancer Institute (NCI) and MEDx software at NCI.  Table IV  shows the results of NCI-3DQI - NCI-MEDx and MGH-3DQI - NCI-MEDx at the first two rows. We take the segmentation results of NCI-MEDx as the ground truth and use DINs on the LRMRI data set. Results in the last row indicate that DINs can achieve similar performance comparing with 3DQI. Notice that the results of NCI-3DQI and MGH-3DQI are finalized with various editing tools, while DINs are not for a fair comparison. 2) Deep CNN-based methods: A comparison between DINs and state-of-the-art medical image segmentation methods is shown in  Table V . One can observe that DINs outperform automated methods by 44%\u201363% and outperform \u201cnnU-Net + Dim output 1\u201d by 29%. Automated methods get low scores, while interactive methods have better performance with the help of user knowledge. The comparison between \u201cnnU-Net + Dim output 1\u201d and \u201cDINs (DIM output 1)\u201d indicates that DINs benefit from the proposed structure of feature extractor adapted to WBMRI. Finally, with the DIM output 2, DINs further increase the DSC by 2%, which suggests the effectiveness of integrating user knowledge into deeper layers. In addition, the p-values of t-test between the results of DINs and other methods are listed for reference. 3) Conventional interactive methods: We compare DINs with some conventional interactive segmentation methods, including Random Walk (RW) [ 24 ], Graph Cut (GC) [ 23 ] and Active Contour (AC) [ 42 ]. RW and GC treat the volume as a discrete static graph, performing segmentation with many positive and negative clicks by solving the linear system (RW) or min-cut (GC) problem. Commonly, to save computation time and reduce irrelevant information, a bounding box is provided before running these conventional approaches. Then the search space can be restricted to a smaller region. Therefore, we implement two versions of DINs: DINs-full.  Feeding the whole 3D volume into DINs for evaluation. DINs-box.  We manually create several bounding boxes in each volume with three criteria: (1) Spatially closer tumors are grouped into the same bounding box. (2) The heights and the widths of bounding boxes are at least 128 pixels, while depths are set as tight to the tumor boundaries as possible that is consistent with users\u2019 behavior. (3) There are no more than five bounding boxes in one case. Fig. 7(a)  presents the trend of DSC for DINs and conventional methods when the interactive points are continuously provided. RW, GC, AC, and DINs-box ran the algorithms within the volume of interest while DINs-full employs the entire 3D volume. In  Fig. 7 , we observe that RW and GC show a low DSC, which is caused by the limited information used to compute features. We notice that DINs-full only has a modest improvement compared with AC since AC needs to set a bounding box and adjust two thresholds for filtering backgrounds, which requires much more user efforts to precisely tune the thresholds. With additional bounding boxes, DINs-box significantly exceeds all of the other three conventional interactive methods. For a detailed comparison, we summarize the type of interactions, DSC, number of interactions, and running time in  Table VI . DINs-full has the minimum requirement of interactions to perform the segmentation, which substantially reduces the complexity of the interaction. With extra bounding boxes, DINs-box further improves segmentation accuracy and reduces both the user burden and the running time. Overall, as the number of interactions increases, DINs improve the segmentation accuracy more stably and successively. Furthermore, a substantial improvement can be made by providing a few bounding boxes for some difficult cases (DINs-box). This implies that DINs are more effective and flexible for interactive segmentation.",
  "cache_level": "full",
  "has_fulltext": true,
  "fetch_date": "2026-02-20 06:58:14",
  "introduction": "I. INTRODUCTION NEUROFIBROMATOSIS type-1 (NF1) is an autosomal dominant neurogenetic disorder characterized by the development of both benign and malignant tumors. The hallmark tumors are neurofibromas, which are histologically benign tumors that arise from the peripheral nerve sheath and involve any body part. Despite benign histology, they can cause significant morbidity due to compression and invasion of nerves and other vital anatomical organs. Neurofibromas can be located deep inside the body and, if asymptomatic, are usually detected by whole-body magnetic resonance imaging (WBMRI) using short tau inversion recovery (STIR) sequences. Based on tumor morphology on MRI, plexiform (invasive or involving multiple nerves) neurofibromas (PNFs) carry an increased risk for transformation into malignant peripheral nerve sheath tumors. Fig. 1  depicts two NF1 cases of WBMRI with the ground truth segmentation of tumor regions contoured in yellow. Accurate detection and evaluation of tumor burden on WBMRI are important for longitudinal tracking of tumor size, which enables accurate assessment of tumor growth and treatment response. However, the detection and segmentation of neurofibroma on WBMRI, particularly PNFs, is associated with three technical challenges. Large number of tumors across the entire body and variable anatomical locations of tumors. Neurofibromas can develop anywhere along peripheral nerves. Their appearance across individuals can vary in number (from none to hundreds) and sizes (from several cubic centimeters to several thousand cubic centimeters). Traditional interactive segmentation methods cannot reasonably handle such a large number of tumors at a time. Conventional segmentation methods for neurofibromas have been proposed in the literature, including histogram thresholding [ 1 ], region growing [ 2 ] using histogram templates, 3D dynamic thresholding level-set [ 3 ]. These interactive segmentation methods are labor-intensive and time-consuming since they involve manual identification of individual tumors by raters and interactive contour correction due to the imperfect segmentation obtained from automated methods. In general, it may take a few minutes to 1\u20132 hours to complete segmentation on WBMRI. Heterogeneous and diffuse tumor architecture. PNFs can be elongated in shape with a characteristic ringlike or septate pattern that typically has a target-like appearance on MRI, with central low signal intensity and peripheral high signal intensity. Recently, deep convolutional neural networks (CNNs) have achieved great success in medical image segmentation, such as U-Net [ 4 ], V-Net [ 5 ], DeepMedic [ 6 ], and nnU-Net [ 7 ]. CNNs have brought a breakthrough for tumor segmentation in the brain [ 8 ], lung [ 9 ], liver [ 10 ], and other organs. Nevertheless, their application in neurofibroma segmentation on WBMRI has been minimal. Besides, CNN-based approaches tend not to generalize well to new data because the targeted neurofibromas may be substantially different in size, shape, intensity, and boundary to adjacent organs in the training and testing data sets. Here, we explore how to embed user interactions into CNNs to improve generalizability for obtaining an accurate and efficient interactive segmentation approach on WBMRI. Guide maps suffer from the distribution shift for variable image sizes. Some CNN-based interactive segmentation approaches [ 11 ], [ 12 ] have been proposed to extract foreground objects interactively. These methods convert user interactions into distance maps utilizing either Euclidean distance transform [ 11 ] (EDT) or geodesic distance transform [ 12 ] (GDT). Typically, training CNNs with image patches and finetune/test on the whole image is a common trade-off between GPU memory and accuracy/inference speed [ 10 ], [ 13 ], [ 14 ]. However, both transformations are sensitive to image sizes, which leads to the distribution shift for guide maps with various sizes and a performance decrease when applied to neurofibroma data. This paper proposes deep interactive neural networks (DINs) for interactive neurofibroma segmentation on WBMRI. We first adapt popular 3D U-Net [ 15 ] to the neurofibroma data on WBMRI by introducing anisotropic convolutional kernels for more accurate tumor-related feature extraction. Then, user interactions are encoded into guide maps as inputs with a distance transformation and embedded into multiple layers of the model for reserving user knowledge in deeper layers. The guide maps are regarded as the local appearance prior and the spatial prior. To avoid the effect of variable image sizes, we propose using exponential distance transform (ExpDT), whose intensity distribution is size-agnostic. With the guide maps, DINs embed users\u2019 prior knowledge into neural networks for correcting segmentation results. Furthermore, to reduce the interaction effort in training and testing processes of DINs, we develop a strategy to simulate user interactions to synthesize various user interactive methods and rapidly explore the best hyper-parameters. It is well known that medical images acquired from different devices have a distribution shift problem that can not be neglected and may lead to poor generalization for CNN models. In this situation, we experimentally demonstrated that DINs have stronger robustness and stability than previous automated and interactive methods. To evaluate DINs, we collected two WBMRI data sets and a local-region MRI (LRMRI) data set from NF1 patients, obtained using different MRI acquisition parameters. Experiments showed that DINs significantly outperformed automated methods by 44% in Dice Similarity Score (DSC), which demonstrated the effectiveness of the CNN-based interactive segmentation. DINs outperformed other CNN-based interactive methods by 29% and ExpDT outperformed other distance transforms (DTs) by 14% in DSC. Furthermore, comparison results on conventional interactive methods suggested that DINs significantly reduced user interactions and running time. The main contributions of the work are summarized as follow: We propose DINs to cope with the challenges of neurofibromas for interactive segmentation on WBMRI. We introduce ExpDT for integrating user interactions into neural networks. ExpDT is size-independent comparing with other common DTs and therefore is more suitable for WBMRI. We propose a deep interactive module to integrate user knowledge into the deeper layers of the model, which effectively enhances the learned features about neurofibromas and improves the segmentation performance. We develop a strategy to simulate user interactions for training 3D interactive neural network models. DINs outperform automated and interactive methods by 44% and 29% in DSC, and ExpDT outperforms other DTs by 14% in DSC. Furthermore, DINs reduce user interactions and running time comparing with conventional methods.",
  "results": "D. Interactive results Two interactive segmentation results of plexiform neurofibromas with DINs are displayed in  Fig. 9 . The ground truth contours (manual segmentation) are red, and the prediction contours are yellow. The positive and negative interactive clicks are marked by red and yellow points, respectively. DINs achieve accurate segmentation of multiple tumors with one click and iteratively improves segmentation with additional interactions. Notice that the  \u03c3  is set to (1, 5, 5) by default, which is suitable for most neurofibroma segmentation situations. In  Fig. 10 , we compare three interactive methods with the same clicks. (Note: A negative click in the second image has a deviated location compared with the other two methods due to the empty prediction with the original location.) Random walk tends to lead to undersegmentation, while graph cut cannot distinguish neurofibromas from normal organs and tends to result in oversegmentation. In comparison, DINs can recognize neurofibromas accurately. The two groups of segmentation results support the advantages of the DINs.",
  "discussion": "VI. CONCLUSION In conclusion, we propose the effective and flexible Deep Interactive Networks with a novel Exponential Distance Transform for neurofibroma segmentation on WBMRIs. The DINs framework efficiently extracts discriminative features of tumors by incorporating user interactions into low-level features and high-level features. The \u201clocal transformation\u201d ExpDT is better equipped to address biased data distribution in medical images. Experiments on the training set and the test set show that the proposed method outperforms conventional interactive methods and performs significantly better than automated and interactive CNN-based methods. Limitations of DINs include the following parts: (1) Like conventional semi-automatic segmentation methods, DINs also need extra editing tools to achieve a acceptable volume measurement; (2) The ExpDT generates guide maps ignoring the image intensities, which may help improve the quality of the guide maps; (3) DINs may failed in some cases such as neurofibromas near the orbits due to the similar intensity. Considering these limitations, integrating the anatomical structure into neural networks and combining the image intensity into guide maps may be the future directions for developing high-performance interactive neural network methods.",
  "upgrade_date": "2026-02-20 07:28:54"
}