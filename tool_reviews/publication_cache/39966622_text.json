{
  "pmid": "PMID:39966622",
  "title": "The development of an artificial intelligence auto-segmentation tool for 3D volumetric analysis of vestibular schwannomas.",
  "abstract": "Linear and volumetric analysis are the typical methods to measure tumor size. 3D volumetric analysis has risen in popularity; however, this is very time and labor intensive limiting its implementation in clinical practice. This study aims to show that an AI-led approach can shorten the length of time required to conduct 3D volumetric analysis of VS tumors and improve image processing accuracy. From Yale New Haven Hospital and public patient recruitment, 143 MRIs were included in the ground truth dataset. To create the tumor models for the ground truth dataset, an image processing software (Simpleware ScanIP, Synopsys) was used. The helper (DPP V1.0) was trained using proprietary AI- and ML-based algorithms and information. A proof-of-concept AI model achieved a mean DICE score of 0.76 (standard deviation 0.21). After the final testing stage, the model improved to a final mean DICE score of 0.88 (range 0.74-0.93, standard deviation 0.04). Our study has demonstrated an efficient, accurate AI for 3D volumetric analysis of vestibular schwannomas. The use of this AI will enable faster 3D volumetric analysis compared to manual segmentation. Additionally, the overlay function would allow visualization of growth patterns. The tool will be a method of assessing tumor growth and allow clinicians to make more informed decisions.",
  "authors": "Noemi Jester; Manwi Singh; Samantha Lorr; Steven M Tommasini; Daniel H Wiznia; Frank D Buono",
  "journal": "Scientific reports",
  "publicationDate": "2025-02-18",
  "doi": "10.1038/s41598-025-88589-x",
  "methods": "Methods Based on our initial trials with a dataset of 10 images, we determined that 150 MRI images were required for a ground truth data set to achieve the desired AI accuracy. This was determined using statistical power analysis based on previous research in DICE score modeling . 16 , 17 This study was approved by the IRB committee at Yale University under reference number 2000032810. All methods were performed in accordance with the relevant guidelines and regulations and patients gave informed consent prior to involvement in this study. Patient recruitment 77 patients were identified through the Yale New Haven Hospital medical database (Fig.\u00a0 1 ). Of these, 24 patients were eligible for inclusion. The patient records of these patients produced 84 MRIs from which VS tumor models could successfully be made. To obtain a diverse set of data and to increase the numbers of patients, the researchers contacted patients through NF-SWN\u00a02 specific Non-Governmental Organisation NF2 BioSolutions. An initial recruitment email was sent out to all members on the mailing list (n\u2009=\u20091000) with a return rate of 7.2% responding with interest. 13 patients were included in the final stage, providing 70 MRIs. Tumor models could be successfully made from 59 MRIs. Fig. 1 Flowchart outlining the patient recruitment process to collect MRI images for segmentation. Inclusion criteria for patients included: patients over the age of 18, patients with a formal diagnosis of NF2-SWN (with either uni- or bilateral vestibular schwannomas) and patients with available MRI scans with the ability to upload these to the server (if recruited from outside of the Yale database). Exclusion criteria included: patients under the age of 18, patients with an undocumented history of NF2-SWN, scans without contrast, scans with large voxel sizes or scan sequences that did not allow for visualization of the inner auditory canal (less than 150 images). Inclusion criteria did not include treatment status or presence of other tumors such as meningiomas, therefore the patient data represented both pre- and posttreatment scans as well as those with meningiomas. From Yale New Haven Hospital and public patient recruitment, 143 MRIs were included in the ground truth dataset. All images used for the POC were T1 weighted, post-contrast MRI scans.  Creation of proof-of-concept data set The quality of images was determined by the researchers and was categorized by voxel size. Scans were categorized into high (less than 0.5\u2009\u00d7\u20090.5\u2009\u00d7\u20091.0), medium (less than 1.0\u2009\u00d7\u20091.0\u2009\u00d7\u20091.0) and low quality (greater than 1.0\u2009\u00d7\u20091.0\u2009\u00d7\u20091.0). To create the tumor models an image processing software (Simpleware, Synopsys, Mountain View, CA) was used. For the proof-of-concept, 110 3D models were used; 66 high quality, 44 medium quality and 6 low quality scans. 3D tumor masks were created for vestibular schwannomas (unilateral or bilateral) as follows (Fig.\u00a0 2 ): Fig. 2 A pathway describing the process used to manually segment the VS tumors from MRI images using the imaging processing software Simpleware ScanIP. To highlight the vestibular schwannomas, a thresholding algorithm was used on selected slices containing the tumor mass. A \u2018split regions\u2019 algorithm was used to isolate the tumors and remove the non-tumorous voxels. Consideration was taken with voxels lining the border of the mask. Missing and surplus voxels were adjusted to include or exclude as necessary using the paint function. After the initial mask creation, the tumors were re-examined in all three planes (coronal, axial, sagittal views) to correct for any missing or extra voxels. All the models were reviewed by a neuroradiologist, who made necessary adjustments. The \u2018volume\u2019 measurement tool was used to calculate the 3D volume (in mm 3 ) of each tumor mask. To visualize the shape, size, and pattern of growth of the masked tumors, a mask was created of the pons at the levels of the tumors. Our segmentation process utilized the Simpleware platform by Synopsys, which integrates proprietary AI-powered auto-segmentation tools. These tools leverage machine learning algorithms trained on large, domain-specific datasets to accurately and efficiently segment complex anatomical structures, including vestibular schwannoma (VS) tumors. To ensure reliability, we validated Simpleware\u2019s output against ground truth annotations using metrics such as the DICE coefficient. Creation of prototype The proof-of-concept (POC) data set used by the engineers at Synopsys consisted of 25 high quality MRIs. The ground truth dataset of 143 MRIs was subdivided into train (80%), validation (10%) and test (10%) groups. The helper (DPP V1.0) was trained using proprietary AI- and ML-based algorithms and information. No tumors identified within the ground truth segmentation were missed by the helper. A final testing stage was completed using 30 new segmentations of MRI scans obtained from NF2 Biosolutions. This stage of training was used for validating the segmentations produced by the tool to verify its ability to identify and segment tumors in previously unseen patient data. Following this testing stage, an additional tool was added to the modeler which corrects the orientation of the images when imported into the software to accommodate different imaging protocols. To compare the accuracy of the AI generated 3D models to the radiologist validated manual segmentation models, a DICE score was calculated. The DICE score calculation was calculated using the equation: DICE Coefficient\u2009=\u20092 * the Area of Overlap / by the total number of pixels in both images. Development of visualization tool To compare the chronological growth of a patient\u2019s tumors, each patient who had multiple scans had their segmented tumor masks imported into a single Simpleware file. An image registration algorithm was used to reformat and align the brain across the DICOM images and the generated 3D tumor models. Accessing the scripting interface in Simpleware, custom code was written to organize bilateral tumors in chronological order and sort them into left and right categories. Plots were generated with a script illustrating the change in size of each tumor over time. Plots indicating percentage change from baseline and volatility were also generated. A color scheme that illustrates chronological tumor growth was developed. The overlapping 3D models of each tumor were displayed in a single color. Models of tumors from earlier scans are displayed in lighter shades whereas models from later scans are displayed in darker shades as seen in Fig.\u00a0 3 . Fig. 3 An example of a tumor visualization using the tool created showing tumor growth. Recent tumor growth is shown by the darker, shaded areas in the model. Finally, Volume measurements were obtained for ten masses using three approaches: manual segmentation, AI-based segmentation, and ellipsoid volume calculation. Ellipsoid volumes were estimated using the formula  . \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$V=\\frac{4}{3}\\pi \\frac{Length}{2}\\frac{Height}{2}\\frac{Width}{2}$$\\end{document} The dimensions used for ellipsoid calculations were based on the maximum observed dimensions of each mass. These measurements were compared to the volumes derived from Manual and AI 3D volume segmentations. Percentage changes were calculated to compare AI and ellipsoid volumes to the manual volumes, to evaluate discrepancies across methodologies. Findings were summarized in Table  1 . Table 1 Comparison of manual, AI and ellipsoid volume segmentations and percent change. Mass number Dimensions (L \u2009\u00d7\u2009 W \u2009\u00d7\u2009 H) Manual volume AI volume Ellipsoid volume % change (ellipsoid vs manual) % change (AI vs manual) 1 0.5\u2009\u00d7\u20090.5\u2009\u00d7\u20090.75 1,390.59 1,401.20 2,545.41 83.04% 0.76% 2 0.5\u2009\u00d7\u20090.5\u2009\u00d7\u20090.75 3,918.43 3,845.14 8,622.21 120.04% 1.87% 3 0.4688\u2009\u00d7\u20090.4688\u2009\u00d7\u20090.9 528.393 489.964 799.481 51.30% 7.27% 4 0.375\u2009\u00d7\u20090.375\u2009\u00d7\u20091.0 247.531 223.031 369.54 49.29% 9.90% 5 0.5078\u2009\u00d7\u20090.5078\u2009\u00d7\u20090.9 1,527.94 1,533.81 2,012.45 31.70% 0.38% 6 0.5078\u2009\u00d7\u20090.5078\u2009\u00d7\u20090.9 45.282 47.421 60.891 34.50% 4.72% 7 0.4688\u2009\u00d7\u20090.4688\u2009\u00d7\u20091.2 2,636.40 2,435.266 3,560.24 35.04% 7.63% 8 0.4688\u2009\u00d7\u20090.4688\u2009\u00d7\u20091.2 1,806.90 1,629.625 2,365.02 30.89% 9.81% 9 0.4297\u2009\u00d7\u20090.4297\u2009\u00d7\u20090.9 76.885 71.425 160.976 109.39% 7.10% 10 0.4297\u2009\u00d7\u20090.4297\u2009\u00d7\u20090.9 303.827 262.013 476.229 56.74% 13.76% Average 60.19% 6.32%",
  "cache_level": "full",
  "has_fulltext": true,
  "fetch_date": "2026-02-19 09:30:59",
  "introduction": "Introduction NF2-related schwannomatosis (previously known as Neurofibromatosis type II; NF2-SWN) is a rare, autosomal dominant disorder caused by mutations in NF2 gene on chromosome 22q12. It is characterized by tumors in the nervous system, such as vestibular schwannomas, spinal meningiomas, and peripheral nerve tumors . Patients with vestibular schwannomas (VS) suffer from hearing loss, tinnitus, facial palsy, and a reduced life expectancy 1 . 2 Radiologic techniques are vital in the diagnosis of NF2-SWN, and regular screening is indicated . Magnetic resonance imaging (MRI) has replaced computed tomography (CT) as the gold-standard imaging for diagnosing and monitoring vestibular schwannomas due to its high sensitivity and specificity 1 , 3 . Recent advancements, such as gadolinium-enhanced T1-weighted (GdT1W) and high-resolution T2-weighted (T2W) imaging, have further improved tumor visualization by enabling clear delineation of the tumor\u2019s contrast and peritumoral characteristics 4 , 5 . 6 T1-weighted MRI is particularly effective in delineating tumor shape, size, location and reflecting mass effects . VS tumors enhance significantly after intravenous gadolinium contrast 1 , 7 . Use of contrast-enhanced, T1-weighted MRI used with T2-weighted or Fluid-attenuated inversion recovery (FLAIR) sequences can distinguish peritumoral cysts and edema, which enhance heterogenously 8 . 9 Given the irregular growth patterns of VS tumors, higher resolution MRIs with small voxel sizes are optimal to capture morphologic details, to allow for accurate 3D volumetric segmentation and modelling. Dombi et al. found that slice thickness should be less than 1\u00a0mm . Volumetric imaging using such parameters has been critical for detecting subtle changes in tumor growth, which traditional 2D imaging might overlook 10 . 6 Linear and volumetric analysis are current methods to measure tumor size. In linear analysis, unidimensional or bidimensional measurements of the largest tumor diameter are assessed on axial or coronal views of MRIs . Numerous factors can decrease sensitivity of linear measurements, including patient orientation, oblique orientations and irregular shape of tumors and high levels of observer variation 10 , 11 . The limitations of linear measurements are exacerbated in cases of asymmetric tumor growth, which may not be accurately captured by single-plane assessments 11 , 12 . 6 Volumetric analysis integrates an additional dimension of measurement. By approximating the tumor as an ellipsoid in every MR slice, volumetric analysis is more sensitive to tumor progression compared to 2D measurements. However, studies exploring volumetric analysis of VS tumors have found that these approximations overestimate volume. Cross-sectional slices of VS tumors deviate from an ellipsoid shape as they develop extra-canalicular components extending into the cerebellopontine angle, adopting the \u201cice cream cone\u201d shape . 13 Considering the limitations of linear and volumetric analysis, 3D volumetric analysis has gained recognition as an accurate method of tracking growth, where tumors are segmented on each MRI slice and the area is multiplied by slice thickness. This eliminates error introduced by approximating or assessing the longest diameter. Despite greater sensitivity , 3D volumetric analysis is not currently practical for clinical use as it requires time intensive manual segmentation 14 . Advanced machine learning algorithms, including convolutional neural networks (CNNs) like U-Net, are being explored to automate this process. These models aim to improve segmentation efficiency while minimizing observer variability, despite challenges such as domain shift across different datasets 13 . The goal of the study is to show that an AI led approach to automate the segmentation and 3D volumetric calculations of these tumors could shorten the time required to conduct 3D volumetric analysis and improve image processing accuracy. 6 , 15",
  "results": "Results A mean DICE score of 0.76 (standard deviation 0.21) was achieved in a proof-of-concept (POC) of the model. After the final testing stage, the final mean DICE score was 0.88 (range 0.74\u20130.93, standard deviation 0.04). Table  2 Table 2 Table showing improvement in DICE scores between the initial tool and the latest version of the AI modeler. Project file Voxel size DICE POC DPP V1.0 Image 1 0.5\u2009\u00d7\u20090.5\u2009\u00d7\u20090.75 0.89 0.90 Image 2 0.5\u2009\u00d7\u20090.5\u2009\u00d7\u20090.9 0.90 0.93 Image 3 0.4688\u2009\u00d7\u20090.4688\u2009\u00d7\u20090.9 0.91 0.92 Image 4 0.375\u2009\u00d7\u20090.375\u2009\u00d7\u20091.0 0.82 0.89 Image 5 0.5078\u2009\u00d7\u20090.5078\u2009\u00d7\u20090.9 0.85 0.93 Image 6 0.4688\u2009\u00d7\u20090.4688\u2009\u00d7\u20091.2 0.86 0.86 Image 7 0.4297\u2009\u00d7\u20090.4297\u2009\u00d7\u20090.9 0.14 0.84 Image 8 0.46875\u2009\u00d7\u20090.46875\u2009\u00d7\u20090.9 0.44 0.88 Image 9 0.4785\u2009\u00d7\u20090.4785\u2009\u00d7\u20091.0 0.47 0.92 Image 10 0.5078\u2009\u00d7\u20090.5078\u2009\u00d7\u20090.9 0.48 0.91 Image 11 0.4833\u2009\u00d7\u20090.4833\u2009\u00d7\u20090.9 0.75 0.87 Image 12 0.5\u2009\u00d7\u20090.5\u2009\u00d7\u20090.75 0.74 0.86 Image 13 0.5\u2009\u00d7\u20090.5\u2009\u00d7\u20090.75 0.78 0.88 Image 14 1.0\u2009\u00d7\u20091.0\u2009\u00d7\u20091.0 0.75 0.74 Image 15 1.0\u2009\u00d7\u20091.0\u2009\u00d7\u20091.0 0.92 0.88 Image 16 0.4688\u2009\u00d7\u20090.4688\u2009\u00d7\u20090.9 0.89 0.84 Image 17 0.4883\u2009\u00d7\u20090.4883\u2009\u00d7\u20091.0 0.88 0.83 Image 18 0.4688\u2009\u00d7\u20090.4688\u2009\u00d7\u20090.5 0.89 0.92 Image 19 0.9766\u2009\u00d7\u20090.9766\u2009\u00d7\u20091.0 0.91 0.88 Image 20 0.4688\u2009\u00d7\u20090.4688\u2009\u00d7\u20090.5858 0.45 0.87 Image 21 0.5\u2009\u00d7\u20090.5\u2009\u00d7\u20091.0 0.91 0.93 Image 22 0.375\u2009\u00d7\u20090.375\u2009\u00d7\u20091.0 0.88 0.89 Image 23 0.4297\u2009\u00d7\u20090.4297\u2009\u00d7\u20091.0 0.90 0.92 Image 24 0.375\u2009\u00d7\u20090.375\u2009\u00d7\u20091.0 0.93 0.92 Mean 0.76 0.88 Standard deviation 0.21 0.04 The table shows the improvement in DICE scores between the initial proof of concept and the final DPP version of the AI modeler in a set of the same 24 images. For example, significant improvement can be seen in Image 7 where the DICE score improved from 0.14 to 0.84.",
  "discussion": "Conclusion Our study has demonstrated an efficient, accurate AI for the 3D volumetric analysis for vestibular schwannomas. The use of this AI will enable faster 3D volumetric analysis compared to manual segmentation. The tool will be a method of assessing tumor growth through volume measurements and allow clinicians to make more informed decisions. One key area of future research will focus on predictive growth of tumors based on the comparison of previous growth rate of analyzed tumors.",
  "upgrade_date": "2026-02-21 02:20:58"
}