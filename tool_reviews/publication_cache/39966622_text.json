{
  "pmid": "PMID:39966622",
  "title": "The development of an artificial intelligence auto-segmentation tool for 3D volumetric analysis of vestibular schwannomas.",
  "abstract": "Linear and volumetric analysis are the typical methods to measure tumor size. 3D volumetric analysis has risen in popularity; however, this is very time and labor intensive limiting its implementation in clinical practice. This study aims to show that an AI-led approach can shorten the length of time required to conduct 3D volumetric analysis of VS tumors and improve image processing accuracy. From Yale New Haven Hospital and public patient recruitment, 143 MRIs were included in the ground truth dataset. To create the tumor models for the ground truth dataset, an image processing software (Simpleware ScanIP, Synopsys) was used. The helper (DPP V1.0) was trained using proprietary AI- and ML-based algorithms and information. A proof-of-concept AI model achieved a mean DICE score of 0.76 (standard deviation 0.21). After the final testing stage, the model improved to a final mean DICE score of 0.88 (range 0.74-0.93, standard deviation 0.04). Our study has demonstrated an efficient, accurate AI for 3D volumetric analysis of vestibular schwannomas. The use of this AI will enable faster 3D volumetric analysis compared to manual segmentation. Additionally, the overlay function would allow visualization of growth patterns. The tool will be a method of assessing tumor growth and allow clinicians to make more informed decisions.",
  "authors": "Noemi Jester; Manwi Singh; Samantha Lorr; Steven M Tommasini; Daniel H Wiznia; Frank D Buono",
  "journal": "Scientific reports",
  "publicationDate": "2025-02-18",
  "doi": "10.1038/s41598-025-88589-x",
  "methods": "Methods Based on our initial trials with a dataset of 10 images, we determined that 150 MRI images were required for a ground truth data set to achieve the desired AI accuracy. This was determined using statistical power analysis based on previous research in DICE score modeling . 16 , 17 This study was approved by the IRB committee at Yale University under reference number 2000032810. All methods were performed in accordance with the relevant guidelines and regulations and patients gave informed consent prior to involvement in this study. Patient recruitment 77 patients were identified through the Yale New Haven Hospital medical database (Fig.\u00a0 1 ). Of these, 24 patients were eligible for inclusion. The patient records of these patients produced 84 MRIs from which VS tumor models could successfully be made. To obtain a diverse set of data and to increase the numbers of patients, the researchers contacted patients through NF-SWN\u00a02 specific Non-Governmental Organisation NF2 BioSolutions. An initial recruitment email was sent out to all members on the mailing list (n\u2009=\u20091000) with a return rate of 7.2% responding with interest. 13 patients were included in the final stage, providing 70 MRIs. Tumor models could be successfully made from 59 MRIs. Fig. 1 Flowchart outlining the patient recruitment process to collect MRI images for segmentation. Inclusion criteria for patients included: patients over the age of 18, patients with a formal diagnosis of NF2-SWN (with either uni- or bilateral vestibular schwannomas) and patients with available MRI scans with the ability to upload these to the server (if recruited from outside of the Yale database). Exclusion criteria included: patients under the age of 18, patients with an undocumented history of NF2-SWN, scans without contrast, scans with large voxel sizes or scan sequences that did not allow for visualization of the inner auditory canal (less than 150 images). Inclusion criteria did not include treatment status or presence of other tumors such as meningiomas, therefore the patient data represented both pre- and posttreatment scans as well as those with meningiomas. From Yale New Haven Hospital and public patient recruitment, 143 MRIs were included in the ground truth dataset. All images used for the POC were T1 weighted, post-contrast MRI scans.  Creation of proof-of-concept data set The quality of images was determined by the researchers and was categorized by voxel size. Scans were categorized into high (less than 0.5\u2009\u00d7\u20090.5\u2009\u00d7\u20091.0), medium (less than 1.0\u2009\u00d7\u20091.0\u2009\u00d7\u20091.0) and low quality (greater than 1.0\u2009\u00d7\u20091.0\u2009\u00d7\u20091.0). To create the tumor models an image processing software (Simpleware, Synopsys, Mountain View, CA) was used. For the proof-of-concept, 110 3D models were used; 66 high quality, 44 medium quality and 6 low quality scans. 3D tumor masks were created for vestibular schwannomas (unilateral or bilateral) as follows (Fig.\u00a0 2 ): Fig. 2 A pathway describing the process used to manually segment the VS tumors from MRI images using the imaging processing software Simpleware ScanIP. To highlight the vestibular schwannomas, a thresholding algorithm was used on selected slices containing the tumor mass. A \u2018split regions\u2019 algorithm was used to isolate the tumors and remove the non-tumorous voxels. Consideration was taken with voxels lining the border of the mask. Missing and surplus voxels were adjusted to include or exclude as necessary using the paint function. After the initial mask creation, the tumors were re-examined in all three planes (coronal, axial, sagittal views) to correct for any missing or extra voxels. All the models were reviewed by a neuroradiologist, who made necessary adjustments. The \u2018volume\u2019 measurement tool was used to calculate the 3D volume (in mm 3 ) of each tumor mask. To visualize the shape, size, and pattern of growth of the masked tumors, a mask was created of the pons at the levels of the tumors. Our segmentation process utilized the Simpleware platform by Synopsys, which integrates proprietary AI-powered auto-segmentation tools. These tools leverage machine learning algorithms trained on large, domain-specific datasets to accurately and efficiently segment complex anatomical structures, including vestibular schwannoma (VS) tumors. To ensure reliability, we validated Simpleware\u2019s output against ground truth annotations using metrics such as the DICE coefficient. Creation of prototype The proof-of-concept (POC) data set used by the engineers at Synopsys consisted of 25 high quality MRIs. The ground truth dataset of 143 MRIs was subdivided into train (80%), validation (10%) and test (10%) groups. The helper (DPP V1.0) was trained using proprietary AI- and ML-based algorithms and information. No tumors identified within the ground truth segmentation were missed by the helper. A final testing stage was completed using 30 new segmentations of MRI scans obtained from NF2 Biosolutions. This stage of training was used for validating the segmentations produced by the tool to verify its ability to identify and segment tumors in previously unseen patient data. Following this testing stage, an additional tool was added to the modeler which corrects the orientation of the images when imported into the software to accommodate different imaging protocols. To compare the accuracy of the AI generated 3D models to the radiologist validated manual segmentation models, a DICE score was calculated. The DICE score calculation was calculated using the equation: DICE Coefficient\u2009=\u20092 * the Area of Overlap / by the total number of pixels in both images. Development of visualization tool To compare the chronological growth of a patient\u2019s tumors, each patient who had multiple scans had their segmented tumor masks imported into a single Simpleware file. An image registration algorithm was used to reformat and align the brain across the DICOM images and the generated 3D tumor models. Accessing the scripting interface in Simpleware, custom code was written to organize bilateral tumors in chronological order and sort them into left and right categories. Plots were generated with a script illustrating the change in size of each tumor over time. Plots indicating percentage change from baseline and volatility were also generated. A color scheme that illustrates chronological tumor growth was developed. The overlapping 3D models of each tumor were displayed in a single color. Models of tumors from earlier scans are displayed in lighter shades whereas models from later scans are displayed in darker shades as seen in Fig.\u00a0 3 . Fig. 3 An example of a tumor visualization using the tool created showing tumor growth. Recent tumor growth is shown by the darker, shaded areas in the model. Finally, Volume measurements were obtained for ten masses using three approaches: manual segmentation, AI-based segmentation, and ellipsoid volume calculation. Ellipsoid volumes were estimated using the formula  . \\documentclass[12pt]{minimal}\n\t\t\t\t\\usepackage{amsmath}\n\t\t\t\t\\usepackage{wasysym} \n\t\t\t\t\\usepackage{amsfonts} \n\t\t\t\t\\usepackage{amssymb} \n\t\t\t\t\\usepackage{amsbsy}\n\t\t\t\t\\usepackage{mathrsfs}\n\t\t\t\t\\usepackage{upgreek}\n\t\t\t\t\\setlength{\\oddsidemargin}{-69pt}\n\t\t\t\t\\begin{document}$$V=\\frac{4}{3}\\pi \\frac{Length}{2}\\frac{Height}{2}\\frac{Width}{2}$$\\end{document} The dimensions used for ellipsoid calculations were based on the maximum observed dimensions of each mass. These measurements were compared to the volumes derived from Manual and AI 3D volume segmentations. Percentage changes were calculated to compare AI and ellipsoid volumes to the manual volumes, to evaluate discrepancies across methodologies. Findings were summarized in Table  1 . Table 1 Comparison of manual, AI and ellipsoid volume segmentations and percent change. Mass number Dimensions (L \u2009\u00d7\u2009 W \u2009\u00d7\u2009 H) Manual volume AI volume Ellipsoid volume % change (ellipsoid vs manual) % change (AI vs manual) 1 0.5\u2009\u00d7\u20090.5\u2009\u00d7\u20090.75 1,390.59 1,401.20 2,545.41 83.04% 0.76% 2 0.5\u2009\u00d7\u20090.5\u2009\u00d7\u20090.75 3,918.43 3,845.14 8,622.21 120.04% 1.87% 3 0.4688\u2009\u00d7\u20090.4688\u2009\u00d7\u20090.9 528.393 489.964 799.481 51.30% 7.27% 4 0.375\u2009\u00d7\u20090.375\u2009\u00d7\u20091.0 247.531 223.031 369.54 49.29% 9.90% 5 0.5078\u2009\u00d7\u20090.5078\u2009\u00d7\u20090.9 1,527.94 1,533.81 2,012.45 31.70% 0.38% 6 0.5078\u2009\u00d7\u20090.5078\u2009\u00d7\u20090.9 45.282 47.421 60.891 34.50% 4.72% 7 0.4688\u2009\u00d7\u20090.4688\u2009\u00d7\u20091.2 2,636.40 2,435.266 3,560.24 35.04% 7.63% 8 0.4688\u2009\u00d7\u20090.4688\u2009\u00d7\u20091.2 1,806.90 1,629.625 2,365.02 30.89% 9.81% 9 0.4297\u2009\u00d7\u20090.4297\u2009\u00d7\u20090.9 76.885 71.425 160.976 109.39% 7.10% 10 0.4297\u2009\u00d7\u20090.4297\u2009\u00d7\u20090.9 303.827 262.013 476.229 56.74% 13.76% Average 60.19% 6.32%",
  "cache_level": "minimal",
  "has_fulltext": true,
  "fetch_date": "2026-02-19 09:30:59"
}