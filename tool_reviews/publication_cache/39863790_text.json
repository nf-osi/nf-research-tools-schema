{
  "pmid": "39863790",
  "abstract": "Deep-learning models have shown promise in differentiating between benign and malignant lesions. Previous studies have primarily focused on specific anatomical regions, overlooking tumors occurring throughout the body with highly heterogeneous whole-body backgrounds. Using neurofibromatosis type 1 (NF1) as an example, this study developed highly accurate MRI-based deep-learning models for the early automated screening of malignant peripheral nerve sheath tumors (MPNSTs) against complex whole-body background. In a Chinese seven-center cohort, data from 347 subjects were analyzed. Our one-step model incorporated normal tissue/organ labels to provide contextual information, offering a solution for tumors with complex backgrounds. To address privacy concerns, we utilized a lightweight deep neural network suitable for hospital deployment. The final model achieved an accuracy of 85.71% for MPNST diagnosis in the validation cohort and 84.75% accuracy in the independent test set, outperforming another classic two-step model. This success suggests potential for AI models in screening other whole-body primary/metastatic tumors.",
  "methods": "Methods Study design and participants This multicenter study used MRI image sets from seven hospitals in China, including Shanghai Ninth People’s Hospital, Shanghai Jiaotong University School of Medicine; Fudan University Shanghai Cancer Center; Shanghai Sixth People’s Hospital, Shanghai Jiaotong University School of Medicine,; Zhongshan Hospital, Fudan University; Huashan Hospital, Fudan University; Tianjin Medical University Cancer Institute and Hospital, Tianjin Medical University; The Fourth Hospital of Hebei Medical University/Hebei Tumor Hospital. Cross-sectional MRI image sets with T2-weighted sequences of patients from 2010 to 2021 with pathologically confirmed diagnoses of PNF/MPNST were eligible for inclusion. Poor quality and nondiagnostic MRI image sets were excluded. There were no limitations on the number of MRI image sets from one individual that could be included, and some image sets included more than one tumor lesion. Given that PNF/MPNST can occur in various body regions among different patients, MRI image sets of different body regions were included as long as the existence of tumor lesions was confirmed. Additionally, another independent MRI image set was adopted for model testing. This multicenter study adhered to the principles of the Declaration of Helsinki and received approval from the institutional review board of Shanghai Ninth People’s Hospital, Shanghai Jiao Tong University School of Medicine (SH9H-2019-T163-2, SH9H-2019-T163-5). As patients were retrospectively recruited, informed consent was exempted by the review board. Clinical manifestations The clinical manifestations of the individuals from Shanghai Ninth People’s Hospital were abstracted for analysis and included age at each MRI examination, sex, pathological diagnosis (PNF or MPNST), presence of spontaneous persistent pain, motor deficits, hard or soft texture, and whether rapid growth was reported in a short period (reported by the patients or their parents). This inclusion was also approved by the aforementioned review board. As the collection of clinical manifestations in other centers was not included in the above ethical approval, we did not include this information in our study for ethical concerns. Furthermore, we have ensured that any data shared in the study cannot be traced back to individual patients, thereby upholding their confidentiality. Image acquisition MRI scans were accumulated within the Picture Archiving and Communication System (PACS) across all participating centers for each patient. In the context of a retrospective multi-center study, inter-site variability emerged due to disparate devices and acquisition protocols, presenting a significant challenge in these types of studies. In this study, the MRI scanners included devices from GE Medical Systems, Siemens, Philips Medical Systems, and United Imaging Healthcare; the magnetic field strengths included 1.5 T and 3.0 T; slice thicknesses varied among different body regions, including 3 mm, 4 mm, 5 mm, 5.5 mm, 6 mm, etc., with or without diffusion-weighted imaging sequences and contrast-enhanced T1-weighted imaging sequences. Given the large diversity in MRI scanners and the fact that this study only used axial T2-weighted fat suppression sequences, we only described the detailed parameters of the axial T2-weighted fat suppression sequence in the four most frequently used MRI devices in this study (Supplementary Table  4 ). Since the parameter varied not only across different devices but also across different body regions, this table used head and neck MRI as an example. Even though the efficacy may have marginally been affected, we believe that the use of a diverse dataset also has its advantages, such as increased generalizability and applicability to real-world scenarios where multiple imaging devices are often used. Image slice selection and quality control Axial slices of MRI with typical tumor lesions were selected. All MRI scans and clinical data were carefully reviewed by a board-certified radiologist and a doctor within the plastic and reconstructive surgery department, both with expertise in NF1. Manual image segmentation and annotation Ground truth for the ROI region was manually established in all selected images. This task was completed by two experienced radiologists (Y.T. and C.Y.) and one doctor (C.W.) with expertise in NF1, using RectLabel (Ryo Kawamura, San Francisco, USA) and Colabeler (Kuaiyi Technology Co., Ltd, Hangzhou, China). All three readers were required to delineate and label the tumor lesions and other tissues/organs that they deemed essential. The number of these labels was then counted and sorted in descending order. The top 10 labels were retained, and all 10 labels were cross approved by all three readers. The classic two-step deep-learning model development U-Net, a convolutional neural network (CNN), was utilized to perform automatic segmentation . The runtime environment for our model was on Python 3.7.1, and the model structure is illustrated in Fig.  30 3 . Among all included images, a batch consisted of 4 randomly selected slices. Each time, the model obtained one batch for training, and an epoch referred to all the images being learned at once. The automatically segmented results from the U-Net model were randomly partitioned into the training (1031; 665 MPNST and 366 PNF) and test (35; 17 MPNST and 18 PNF) sets. ResNet 18, an 18-layer deep CNN model, was employed for our differential diagnosis model (the model structure is shown in Fig.  3 ) . The model was developed using PyTorch. 31 The one-step deep learning model development for whole-body tumor identification Another deep learning algorithm, You Only Look Once-v5 (YOLO-v5), was adopted and improved to establish a PNF/MPNST detection and diagnosis system. The model structure is shown in Supplementary Fig.  4 , while the training and prediction process is shown in Supplementary Fig.  5 . In the training process, we developed two distinct models: one with only PNF/MPNST labels and the other with all ten labels included. Due to their similarities on T2-weighted images, the gland and lymph tissue were combined into a single label. Three different loss values were calculated for performance evaluation: box loss, object loss, and class loss. The one-step deep learning model used CIOU (Completed IoU) to calculate the box loss. Model interpretability The Gradient-weighted Class Activation Mapping can visualize the predictive basis of CNN-based deep learning models by generating saliency maps, which was normally adopted as a method to visually explain these models . By the Grad-CAM, it was possible to observe which regions in the MRI contributed to the MPNST diagnosis. 32 Statistical analysis The included clinical symptoms were all categorical variables, and the chi-squared test or Fisher’s exact test was used for different types of data.  P  values < 0.05 were considered statistically significant, and  P  values < 0.01 were considered highly statistically significant.",
  "introduction": "",
  "results": "",
  "discussion": "",
  "fetched_at": "2026-02-11T23:39:28.027061",
  "abstract_length": 1135,
  "methods_length": 7047,
  "introduction_length": 0,
  "results_length": 0,
  "discussion_length": 0
}