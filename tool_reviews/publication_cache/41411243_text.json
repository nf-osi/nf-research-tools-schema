{
  "pmid": "PMID:41411243",
  "title": "PERADIGM: Phenotype embedding similarity-based rare disease gene mapping.",
  "abstract": "Identifying genes associated with rare diseases remains challenging due to the scarcity of patients and the limited statistical power of traditional association methods. Here, we introduce PERADIGM ( Phenotype Embedding similarity-based RAre DIsease Gene Mapping), a novel framework that leverages natural language processing techniques to integrate comprehensive phenotype information from electronic health records for rare disease gene discovery. PERADIGM employs an embedding model to capture relationships between ICD-10 codes, providing a nuanced representation of individual phenotypes. By utilizing patient similarity scores, it enhances the identification of candidate genes associated with disease-specific phenotypes, surpassing conventional methods that rely on binary disease status. We applied PERADIGM to the UK Biobank dataset for three rare diseases: autosomal dominant polycystic kidney disease (ADPKD), Marfan syndrome, and neurofibromatosis type 1 (NF1). PERADIGM identified additional candidate genes associated with ADPKD-related and Marfan syndrome-related phenotypes, some of which are supported by existing literature, and demonstrated enhanced signal detection for NF1-specific phenotypes beyond traditional methods. Our findings demonstrate the potential of PERADIGM to identify genes associated with rare diseases and related phenotypes by incorporating phenotype embeddings and patient similarity, providing a powerful tool for precision medicine and a deeper understanding of rare disease genetics and clinical manifestations.",
  "authors": "Wangjie Zheng; Yuhan Xie; Jianlei Gu; Hongyu Li; Stefan Somlo; Whitney Besse; Hongyu Zhao",
  "journal": "PLoS genetics",
  "publicationDate": "2025-12",
  "doi": "10.1371/journal.pgen.1011976",
  "methods": "Materials and methods UK Biobank 200K dataset and genotype data quality control We utilized the UK Biobank 200K dataset [ 4 , 50 ] in our analysis. To mitigate potential confounding effects due to population stratification, we restricted our analysis to individuals of European ancestry. We applied several filtering criteria to ensure data quality and completeness. Specifically, we excluded individuals who lacked Hospital inpatient data or whole-exome sequencing data. To eliminate potential biases due to sample relatedness, we also removed related individuals from the UK Biobank dataset. Specifically, we used the kinship coefficients provided by UK Biobank to identify all pairs of related participants and excluded individuals with first- or second-degree relationships. Within each related family, one individual was randomly retained to ensure that the final analysis cohort consisted entirely of unrelated samples. After applying these filters, our final study cohort comprised 121,330 individuals of European ancestry. This refined dataset ensures a more homogeneous population with comprehensive phenotypic and genetic information, thereby enhancing the reliability and interpretability of our subsequent analyses. To ensure the quality and reliability of the rare variant analysis, we implemented stringent quality control (QC) measures on the whole-exome sequencing (WES) data using PLINK [ 51 ]. Our QC protocol comprised several steps. We first removed variants with a minor allele frequency (MAF) exceeding 0.01, thereby retaining only rare variants for subsequent analysis. We then excluded variants that significantly deviated from the Hardy-Weinberg equilibrium (HWE), with a threshold of p < 1e-6. A significant departure from HWE can indicate genotyping errors or population stratification. Furthermore, we removed samples with missing sex information. Following these QC steps, we identified all rare predicted loss of function (pLoF) variants. These included stop-gain, stop-loss, frameshift insertion, frameshift deletion, and essential splice variants. This allowed us to focus on potentially impactful genetic alterations [ 52 ]. To reduce the impact of somatic mutations, we added a filtering step. Although UK Biobank WES data are derived from blood samples, prior studies [ 53 ] have shown that some rare variants may reflect somatic rather than germline mutations. Since somatic variants are more frequent in older individuals, we compared the age distributions of rare LoF variant carriers and non-carriers for each gene using the Wilcoxon rank-sum test, followed by Bonferroni correction. Genes whose carriers were significantly older were flagged as potential CHIP-related signals. Three genes, ASXL1, TET2, and DNMT3A, met this criterion and were removed from our genome-wide analyses. This filtering step enhances the robustness of our results by minimizing confounding from age-related somatic mutations and comorbidity-driven phenotypic similarity. Embedding model Embedding learning and semantic matching have a rich history in natural language processing. Mikolov et al. introduced the continuous Bag-of-Words (CBOW) and Skip-gram models, collectively known as Word2Vec, to represent words in a vector space [ 22 ]. These neural network-based models achieve state-of-the-art performance in measuring syntactic and semantic word similarity. Many studies have leveraged Word2Vec to embed medical concepts for patients using Electronic Health Record (EHR) corpora, directly utilizing textual medical records as input. In our embedding analysis, we applied the CBOW Word2Vec model to embed the ICD-10 phenotype data from the UK Biobank. The CBOW model is an architecture used in word embedding where the surrounding context words are used to predict a target word. In CBOW, a window of context words around a target word is input to the model, and the goal is to predict the central (target) word from these context words. The model optimizes weights to maximize the probability of predicting the correct target word based on the given context. This approach is particularly well-suited for embedding ICD-10 codes based on the surrounding diagnosis records of individual patients. It effectively captures the contextual relationships between phenotypes, enabling the representation of medical concepts in a dense, continuous vector space. By leveraging these contextual relationships, the model can potentially uncover latent patterns and associations within the medical data that might not be immediately apparent through traditional analysis methods. Embedding for ICD-10 codes We aim to map phenotypes onto a static high-dimensional space, enabling numerical representation of their characteristics and facilitating similarity measurements between different phenotypes. We employed the Word2Vec embedding model to obtain static embedding vectors for the phenotypes. In the UK Biobank database, hospital inpatient data are recorded in the form of ICD-10 codes, each representing a specific disease. For instance, Q61.2 denotes, Polycystic kidney, adult type. Consequently, each patient\u2019s record yields a sequence of ICD-10 codes, comprehensively describing their longitudinal inpatient condition. Based on this information, we developed the following approach to embedding the ICD-10 codes. For each ICD-10 code, we extracted keywords from its description, excluding punctuation and English stopwords. This process generated a vector of words for each patient based on his/her ICD-10 descriptions, with each word serving as a token in the training dataset. Each patient\u2019s ICD-10 description was treated as a sentence. The output comprised embedding vectors for each word appearing in the inpatient dataset. We then employed an average embedding to derive the embedding vector for each ICD-10 code. This approach not only captured sequential information between different description tokens for each ICD-10 code but also leveraged detailed word tokens when two ICD-10 codes contain similar words. Embedding for individual using ICD-10 codes After obtaining the embedding vector for each ICD-10 code in the UK Biobank data, we proceeded to embed individuals using a weighted average embedding approach. This method enhances simple averaging of ICD-10 code embedding vectors by focusing only on less common ICD-10 codes (frequency  ) and assigning differential weights to these codes. We assigned weights by considering two pieces of information for an ICD code: (1) the significance level of each code with respect to the target disease, a process to be detailed in subsequent sections, and (2) the information content of each ICD-10 code, derived from its frequency. \u2264 0.01 For risk gene mapping, we focus on a specific disease of interest. Different phenotypes have varying degrees of associations with the target disease. Consequently, simply averaging all available ICD-10 embeddings to represent an individual\u2019s overall phenotype embedding may be less effective to capture its relevance to the target disease. A more informative approach to characterizing an individual\u2019s phenotypic profile in relation to a target disease involves assigning differential weights to distinct ICD-10 codes, with higher weights indicating a stronger relationship with the target disease. Target disease relevance is captured through the logistic regression model: l o g i t ( c i j ) = \u03b1 + \u03b2 d j + \u03b3 z j , (1) where  c  denotes the i-th ICD-10 code status of individual j,  ij d  represents the target disease status of individual j, and  j z  is the vector of covariates, specifically age and sex. We conducted a comprehensive scan of all ICD-10 codes in the UK Biobank inpatient dataset for the disease of interest, calculating a p-value for each ICD-10 code. Subsequently, we utilized these p-values to derive the weight for each ICD-10 code. By employing this weighting scheme, ICD-10 codes exhibiting a more significant association with the disease of interest are assigned larger weights, thereby playing a more prominent role in the individual embedding process. We also considered each ICD-10 code\u2019s prevalence, denoted as  j r , in the embedding for each individual. k I C k = \u2212 log ( r k ) , (2) This formulation of information content assigns higher values to rarer phenotypes, reflecting our assumption that rarer phenotypes carry more information about rare diseases. The weight  w  for the  k k -th ICD-10 code is then calculated as: w k = S i g m o i d ( \u2212 log ( p -value ( k ) ) ) \u00b7 I C k , (3) where the  p -value represents the significance level of the  k -th ICD-10 code in relation to the disease of interest. We use a sigmoid function to map the  p -value onto a [0.5, 1] scale, with greater weights indicating phenotypes more relevant to the disease of interest. The rationale behind this weighted average embedding is twofold. First, it aims to capture the differential importance of various phenotypes in relation to specific diseases, acknowledging that different phenotypes contribute distinctly to each disease. Second, it assigns more weight to rare ICD-10 codes to prevent common ICD-10 codes from overwhelming the information provided by less frequent, but potentially more informative, codes. This approach is based on the assumption that for rare diseases, the rare phenotypes each individual exhibits will carry more information about the disease. Consequently, this method ensures a more comprehensive and disease-specific representation of each individual\u2019s phenotypic profile, potentially enhancing the detection of subtle disease associations. With such defined weights, the embedding vector for an individual  i  is calculated as: D i = \u2211 k = 1 n i w k e k \u2211 k = 1 n i w k , (4) where  D  is the embedding vector for individual  i i ,  n  is the total number of less common ICD-10 codes (frequency  i ) recorded in individual  \u2264 0.01 i ,  e  is the embedding vector of the  k k -th ICD-10 code, and  w  is the weight of the ICD-10 code  k e . This equation shows how we represent an individual using weighted ICD-10 code embeddings. k Risk gene mapping Based on the phenotype embedding of each individual, we can assign each gene a risk score for a disease of interest by investigating the similarity of the phenotype embeddings from rare LoF variant carriers with those having the target disease. A larger risk score indicates a higher likelihood that the candidate gene is associated with the disease of interest. Unlike other gene prioritization tools based on pathways or other biological criteria, we calculated the risk score solely based on phenotype similarities. This is accomplished in four steps. First, we extracted all the rare Loss of Function (LoF) variant carriers for each candidate gene, along with their genotype and phenotype information. Second, we extracted all individuals diagnosed with the target disease and their phenotype information. Third, we used the method described in the previous section to embed the LoF set carriers and disease patients, obtaining their embedding representations. Fourth, we calculated the disease risk score by comparing the phenotype similarity at the individual level between the different genes\u2019 LoF set carriers and the diseased individuals. Our underlying assumption is that greater similarity between disease patients and gene LoF set carriers at the phenotype embedding level indicates higher pathogenicity of the gene for the disease of interest. This is based on the hypothesis that rare LoF variants have a large effect size on the phenotype compared to common variants. Notably, we considered not only the disease status as a binary value but all relevant phenotype information related to the disease, providing a more comprehensive and reasonable approach. Finally, we ranked each gene\u2019s risk score based on the calculated average similarity score. S i = 1 m ( \u2211 k = 1 m c o s i n e ( D i , D k ) ) , (5) where  S  is the average similarity score for individual  i i  compared to the disease patients group,  m  is the number of patients in the disease of interest comparison group,  D  is the embedding vector for each individual, and the   function represents cosine similarity, commonly used in calculating the similarity between two embedding vectors. Based on the similarity score for each LoF mutation carrier, we can calculate the overall score for each candidate gene as Cosine ( ) R G i = \u2211 k = 1 n G i S k n G i , (6) where   is the risk score of gene  R G i i  to the disease of interest, and   is number of LoF carriers for gene  n G i i . For each observed risk score, we employed random sampling to determine its significance level. Under the null hypothesis ( H 0 ), we derived an empirical distribution of the risk score for the target gene by repeatedly randomly selecting  n  samples from the UK Biobank 200K inpatient dataset and computed the risk score for each group. This process was repeated 10,000 times to construct the empirical risk score distribution for gene  i i  under the null hypothesis for the target disease. The estimated p-value for the observed risk score is derived by calculating the Z-score using the formula: Z = R G i \u2212 \u03bc 0 \u03c3 . (7) where   is the observed risk score,  R G i  is the average of the risk scores from randomly sampled sets of individuals, and  \u03bc 0 \u03c3  is the standard deviation of the simulated risk scores. The p-value is then computed from the standard normal distribution. We applied a one-tailed test with a significance level of 0.05 and used the Bonferroni correction to control for multiple testing, assessing whether the gene\u2019s risk score is significantly higher than expected by chance. Intra-group similarity calculation To elucidate the overall phenotype patterns within the disease group and among carriers of rare LoF variants of a candidate gene, we calculated the intra-group phenotype similarity in the embedding space. This analysis aimed to explore whether individuals within these groups share greater phenotypic similarity compared to randomly selected individuals from the UK Biobank. First, we considered all individual pairs within the target group and calculated similarity scores for each pair within the target group. We then randomly selected an equal number of individuals from the UK WES 200K excluding the target group, and calculated pairwise similarity scores. A difference in the similarity score box plot of the two groups would suggest that the given group exhibits a distinct intra-group phenotype pattern compared to the overall dataset. For example, this analysis could reveal whether carriers of rare LoF variants in the  PKD1  gene demonstrate greater phenotypic similarity to each other than a randomly selected control group from the UK Biobank. Disease cohort definition For each target disease, we defined the case cohort based on the corresponding International Classification of Diseases, 10th Revision (ICD-10) codes recorded in the UK Biobank electronic health records. Individuals with at least one record of the disease-specific ICD-10 code were included as cases, while all other participants were considered part of the background control population. This definition ensures that cohort membership is determined directly from standardized diagnostic codes without requiring additional phenotype modeling or manual curation. Specifically, autosomal dominant polycystic kidney disease (ADPKD) cases were identified using ICD-10 codes Q61.2 and Q61.3; Marfan syndrome cases were identified using Q87.4; and neurofibromatosis type 1 (NF1) cases were identified using Q85.0. For each disease, individuals carrying any of these codes were assigned to the corresponding disease cohort. Control individuals were drawn from the remaining participants who did not possess the disease-specific ICD-10 codes. All disease and control cohorts were restricted to unrelated individuals of European ancestry, as defined by UK Biobank-provided kinship coefficients and ancestry principal components, to minimize population structure and relatedness confounding. Type I error rate control simulation Assessing the type I error rate of PERADIGM is essential for establishing the reliability of our framework. We conducted comprehensive simulations to evaluate calibration under the null hypothesis. For each disease (ADPKD, Marfan syndrome, and NF1), we used the observed distribution of target-disease similarity scores to generate simulated datasets. In each replicate, individuals were randomly assigned to synthetic \u201cgene carrier groups\u201d that matched the observed carrier-count distribution of real genes (denoted  N ). A pseudo gene-level risk score was then calculated as the average similarity score across individuals within each simulated group, and the same random-sampling association test used in the real analysis was applied to obtain null  g p -values. We assessed type I error control through four complementary analyses: (1) QQ plots were drawn to visually inspect inflation or deflation in the null  p -value distribution. (2) Empirical type I error rates were computed as the proportion of null  p -values below nominal thresholds (e.g., 0.05 and 0.01). (3) Kolmogorov\u2013Smirnov (KS) tests were performed to evaluate deviations from the expected uniform distribution. (4) The genomic inflation factor ( \u03bb ) was calculated to measure systematic inflation or deflation, with values near 1 indicating proper calibration. All simulation results are provided in the  S1 Text ,  S1 Table , and  S1 Fig . Alternative weighting schemes analysis To evaluate the impact of weighting schemes on individual embeddings, we conducted additional analyses to systematically assess how different weighting strategies influence the PERADIGM framework. We compared our original weighting scheme with four alternative strategies: (1)   \u00d7  w = Sigmoid ( \u2212 log ( effect\u00a0size ) ) , (2)  IC , (3)  w = Sigmoid ( \u2212 log ( p -value ) ) , and (4)  w = IC . Together with the original approach, these five schemes incorporate varying combinations of disease-association strength (via  w = Sigmoid ( \u2212 log ( effect\u00a0size ) ) p -values or effect sizes) and phenotype information content (IC). The additional schemes were designed to disentangle the relative contribution of association strength and information content to the weighting mechanism in PERADIGM. For each scheme, we generated corresponding ICD-10 code weights and evaluated pairwise consistency among them by computing Pearson correlation coefficients across all weighting matrices. This analysis allowed us to assess whether the different formulations capture similar disease-relevant information or emphasize distinct aspects of the phenotype space. In addition, we re-ran the PERADIGM pipeline using each weighting scheme to examine how weighting choice influences downstream gene-level results and overall calibration. The consistency of significant findings across these weighting variants provides an indication of PERADIGM\u2019s robustness to the specific choice of weighting formulation. All the alternative weighting scheme analysis results are provided in the  S1 Text ,  S2 Fig , and  S3 Fig .",
  "cache_level": "minimal",
  "has_fulltext": true,
  "fetch_date": "2026-02-19 09:31:32"
}