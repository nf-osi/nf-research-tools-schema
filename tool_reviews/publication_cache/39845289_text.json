{
  "pmid": "39845289",
  "abstract": "OBJECTIVE: Dimensionality reduction techniques aim to enhance the performance of machine learning (ML) models by reducing noise and mitigating overfitting. We sought to compare the effect of different dimensionality reduction methods for comorbidity features extracted from electronic health records (EHRs) on the performance of ML models for predicting the development of various sub-phenotypes in children with Neurofibromatosis type 1 (NF1). MATERIALS AND METHODS: EHR-derived data from pediatric subjects with a confirmed clinical diagnosis of NF1 were used to create 10 unique comorbidities code-derived feature sets by incorporating dimensionality reduction techniques using raw International Classification of Diseases codes, Clinical Classifications Software Refined, and Phecode mapping schemes. We compared the performance of logistic regression, XGBoost, and random forest models utilizing each feature set. RESULTS: XGBoost-based predictive models were most successful at predicting NF1 sub-phenotypes. Overall, features based on domain knowledge-informed mapping schema performed better than unsupervised feature reduction methods. High-level features exhibited the worst performance across models and outcomes, suggesting excessive information loss with over-aggregation of features. DISCUSSION: Model performance is significantly impacted by dimensionality reduction techniques and varies by specific ML algorithm and outcome being predicted. Automated methods using existing knowledge and ontology databases can effectively aggregate features extracted from EHRs. CONCLUSION: Dimensionality reduction through feature aggregation can enhance the performance of ML models, particularly in high-dimensional datasets with small sample sizes, commonly found in EHRs health applications. However, if not carefully optimized, it can lead to information loss and data oversimplification, potentially adversely affecting model performance.",
  "methods": "Materials and Methods EHR-derived data from pediatric subjects with a confirmed clinical diagnosis of NF1 were used to create 10 unique comorbidities code-derived feature sets by incorporating dimensionality reduction techniques using raw International Classification of Diseases codes, Clinical Classifications Software Refined, and Phecode mapping schemes. We compared the performance of logistic regression, XGBoost, and random forest models utilizing each feature set. Materials and methods With the approval of the Washington University Institutional Review Board (protocol #201706112), EHR data were extracted from the Research Data Core at Washington University School of Medicine, a data lake containing retrospective clinical records from Washington University Medicine and BJC Healthcare, including those from Barnes-Jewish Hospital and St Louis Children’s Hospital. All subjects were younger than 18 and had a confirmed clinical diagnosis of NF1 (ICD10-CM code Q85.01). The extracted data included features from structured data, comprising all diagnosed ICD10-CM codes within the cohort and demographic information. We created 10 datasets for comparison, keeping sex and race constant across each while varying the ICD-10-CM-derived features by using different feature reduction and aggregation methods to modify the diagnoses and group them into their clinical context-based feature sets ( Figure 1 ). To ensure that the results were not phenotype-specific, three different sub-phenotypes (OPG, ADHD, and scoliosis) were chosen for analysis. Importantly, while measures have been taken to ensure that the results are as unbiased and accurate as possible, the resulting predictive models and results were not evaluated for clinical accuracy. Figure 1. ICD10-CM feature aggregation and reduction workflow.  Graphical representation of the various feature aggregation and reductions that result from ICD10-CM diagnoses. Data inclusion for predictive modeling Individuals diagnosed with OPG, ADHD, or scoliosis were identified using ICD10-CM codes. Physician-experts in the field of NF1 (S.M.M. and D.H.G.) curated a list of ICD10-CM codes for each of the 3 conditions ( Table S1 ). Unique feature sets were created for training and evaluating the predictive models for OPG, ADHD, and scoliosis. For each of these conditions, individuals who were not diagnosed with the condition within the timeframe of the extracted data had their full available diagnosis history used to determine the presence or absence of each of the ICD10-CM diagnoses present in the study cohort. Individuals diagnosed with a condition had only their diagnosis history included in training the prediction model until their diagnosis was rendered. The datasets were constructed in this way to prevent leakage of the outcome variables into the dataset used for prediction. Diagnosis feature aggregation and reduction Various dimensionality reduction methods created 10 total feature sets. Seven were built using methods including aggregating features based on ICD10-CM coding hierarchies, mappings that group together hierarchical ICD10-CM codes, and prevalence-based filtering to keep the most common comorbidities. The remaining 3 feature sets were generated using unsupervised clustering and PCA techniques. ( Table 1 ; further described below). Table 1. Feature set names, descriptions, and  N  features. Feature set acronym Feature set Description Features ( n ) ICD10-1 ICD10-CM Base Base feature set with each ICD10-CM diagnosis code in the cohort represented as a binary feature 2982 ICD10-2 ICD10-CM Selected Subset of features from “ICD10-CM Base” based on a individual prevalence greater than 1% 477 ICD10-3 ICD10-CM First 3 Maps ICD10-CM code features from “ICD10-CM Base” by using only the first 3 digits 786 Phecode-1 Phecode expanded Map all ICD10-CM code features from “ICD10-CM Base” to lowest level Phecode categories 861 Phecode-2 Phecode expanded selected Subset of features from “Phecode Expanded” based on an individual prevalence greater than 1% 299 Phecode-3 Phecode exclusive Map all ICD10-CM code features from “ICD10-CM Base” to highest level Phecode categories 22 CCSR CCSR Categorize ICD10-CM code features from “ICD10-CM Base” using CCS standard mapping 309 Clustered-1 K-means clustered K-means clustering-based feature reduction using Lloyd algorithm and “K-means++” centroid initialization 252 Clustered-2 Hierarchical clustered Hierarchical clustering-based feature reduction using Euclidean distance and Ward linkage 232 Clustered-3 PCA PCA-based feature reduction 98 Abbreviations: ICD = International Classification of Diseases; ICD10-CM = International Classification of Diseases, Tenth Revision, Clinical Modification; CCSR = Clinical Classifications Software Refined; PCA = Principal Component Analysis. Feature sets using ICD-based methods The base dataset (ICD10-1) included all 2982 unique ICD-10-CM codes within the cohort represented as binary variables. We used Phecode and CCSR, aggregation and reduction methods that group ICD-10 codes into standardized, clinically meaningful concepts  ( 5–8 Table 1 ). Phecode and CCSR map codes into concepts, or features, by aggregating codes that are clinically similar. Each has different hierarchies that aggregate and reduce the feature space in different ways. Feature sets using clustering and PCA methods Each of these feature sets was created using a different method, namely k-means clustering,  hierarchical clustering, and PCA 17  ( 18 Table 1 ). The matrix for clustering was a square matrix [2982*2982], holding the counts of every pairwise set of ICD10-CM codes in our cohort. In this matrix, cell  C i ,     contains the number of individuals that have cooccurring diagnoses of both  j i  and  j  ICD10-CM codes. For k-means and hierarchical clustering, the elbow method was used to determine the optimal k clusters, where each cluster contains diagnoses that frequently co-occur in individuals in our cohort. Yellowbrick, a ML visualization library, was used for this purpose.  For k-means clustering, we used the Lloyd algorithm with K-Means++ centroid initialization, which samples and assigns initial centroids based on the maximum squared distance from each other. Hierarchical clustering used Euclidean distance and Ward linkage. For PCA, we set a threshold of 95% variance explained to select the number of principal components to use ( 19 N  = 98). ML models The effect of the different feature sets on predictive modeling was evaluated using 3 different algorithms: logistic regression,  random forest, 20  and XGBoost. 21  Model selection and hyperparameter tuning were done using nested cross-validation and randomized search with 100 parameter space samples for each inner fold. From this, 5 parameter sets were generated—one for each top-performing model from each outer fold was returned. The highest performing parameter set according to F1-score was selected as the final parameter set and evaluated by averaging performance over a series of 5-fold cross-validation iterations. The splits were kept the same across models and datasets to ensure an unbiased comparison of performances. The evaluation metrics were area under the receiver operating characteristic curve (AUROC), average precision, and F1 score. 22 Additionally, when mapping to different feature sets, specific ICD10-CM codes were filtered out to prevent leakage of the outcome variable into the set of predictor variables. All feature sets were created by starting with the base ICD10-CM dataset (ICD10-1), removing the ICD10-CM codes corresponding specifically to the outcome variable, then mapping the remaining codes to each different feature set. For example, a feature in Phecode Expanded named “Cancer of brain and nervous system” encompassed diagnoses related to brain and nervous system cancers, including several codes used to identify OPG subjects in our cohort. To keep this feature in the model, those codes used to identify subjects with OPG in our data were removed before mapping so they did not leak into the dataset. Similarly, for the ICD10-1 and ICD10-2 OPG, ADHD, and scoliosis datasets, the identifying codes for these sub-phenotypes were removed from their respective feature space. Statistical analysis Statistical testing was conducted to compare the performance between feature sets. Friedman’s test, a nonparametric test of repeated measures, is commonly used for comparing multiple classifiers over multiple datasets.  More specifically, Friedman’s test is appropriate in situations where the independent variable is binary, there are evaluation metrics from multiple testing sets, and more than 2 models are being compared. These conditions apply to our study. The post hoc test selected was the Conover test, which is commonly used to perform pairwise comparisons following Friedman’s test. 23 24 Initially, we used Friedman’s test to compare AUROC values from each feature set across different conditions and models. Subsequently, the Conover test, with Bonferroni correction for multiple comparisons, was performed to identify statistically significant pairwise differences. A significance threshold of 0.05 was used for all tests. Feature importance analysis We analyzed the most important features of the various feature sets to determine, for each outcome variable, whether the most critical features of the feature space are similar across feature sets. This similarity was quantified by the number of features shared by the top 10 most important features of each feature set as identified by XGBoost. However, it is challenging to perform these comparisons for feature sets derived by grouping ICD10-CM codes (including everything except for ICD10-CM Base [ICD10-1] and ICD10-CM Selected [ICD10-2]). For this reason, the top 10 features of ICD10-CM Base were chosen as the baseline against which the 9 other feature sets were compared instead of comparing all pairwise combinations of the ten feature sets. For the feature sets that grouped ICD10-CM codes into higher-level features, a feature was counted as shared if the feature encompasses at least 1 code from the top 10 features of ICD10-1. For example, if 1 of ICD10-1’s 10 most important features for a prediction was “A01.1,” and 1 of CCSR’ 10 most important features was titled “Example Feature,” which was made up of codes “A01.1,” “B01.1,” and “C01.1.” Since this CCSR feature included “A01.1,” then this was counted as a shared feature. The total number of shared features between ICD10-1 and CCSR would be the number of times this occurs out of ten, since only the top ten most important features were analyzed. For ICD10-2, the only other feature set with singular ICD10-CM codes as features and did not group, a feature was counted as shared if the same code from ICD10-1 was present in ICD10-2. In this manner, the total number of shared features between ICD10-1 and ICD10-2 was equivalent to the intersection of their top 10 most important features. For PCA, feature overlap must be handled differently because the ICD10-CM codes that define the components are not mutually exclusive. As a result, feature overlap considers only the top 10 ICD10-CM codes by magnitude of coefficient of linear combination for each component. HoloViews, a data analysis and visualization library, was used to generate the shared feature plots. 25 Feature sets using ICD-based methods The base dataset (ICD10-1) included all 2982 unique ICD-10-CM codes within the cohort represented as binary variables. We used Phecode and CCSR, aggregation and reduction methods that group ICD-10 codes into standardized, clinically meaningful concepts  ( 5–8 Table 1 ). Phecode and CCSR map codes into concepts, or features, by aggregating codes that are clinically similar. Each has different hierarchies that aggregate and reduce the feature space in different ways. Feature sets using clustering and PCA methods Each of these feature sets was created using a different method, namely k-means clustering,  hierarchical clustering, and PCA 17  ( 18 Table 1 ). The matrix for clustering was a square matrix [2982*2982], holding the counts of every pairwise set of ICD10-CM codes in our cohort. In this matrix, cell  C i ,     contains the number of individuals that have cooccurring diagnoses of both  j i  and  j  ICD10-CM codes. For k-means and hierarchical clustering, the elbow method was used to determine the optimal k clusters, where each cluster contains diagnoses that frequently co-occur in individuals in our cohort. Yellowbrick, a ML visualization library, was used for this purpose.  For k-means clustering, we used the Lloyd algorithm with K-Means++ centroid initialization, which samples and assigns initial centroids based on the maximum squared distance from each other. Hierarchical clustering used Euclidean distance and Ward linkage. For PCA, we set a threshold of 95% variance explained to select the number of principal components to use ( 19 N  = 98).",
  "introduction": "",
  "results": "",
  "discussion": "",
  "fetched_at": "2026-02-11T23:39:19.929828",
  "abstract_length": 1946,
  "methods_length": 13006,
  "introduction_length": 0,
  "results_length": 0,
  "discussion_length": 0
}